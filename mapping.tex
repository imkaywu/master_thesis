%% The following is a directive for TeXShop to indicate the main file
%%!TEX root = diss.tex

\chapter{A Mapping of 3D Reconstruction}
\label{ch:3DRecon_Mapping}
Most vision work focuses on developing algorithmic novelties, and as we have mentioned, very few investigate the rigorous conditions under which the algorithms themselves work. Thus, this knowledge is only known empirically, without a rigorous definition of the problem conditions. This relation between problem space and algorithms (termed as \textit{mapping}) is one of the key components of the interpreter, and is responsible for selecting one of the best possible algorithms based on described problem condition. The mapping is essentially a look-up table that returns a list of successful algorithms given a problem condition. This section builds upon the description proposed in Chapter~\ref{ch:3DRecon_Desc}, and attempts to find the problem conditions surrounding each algorithm empirically. To achieve this goal, we need to evaluate the performance of algorithms under varied problem conditions.

Two challenges need to be addressed, the first of which is to evaluate the performance of algorithms under a variety of problem conditions. This requires a dataset containing objects captured for between-category algorithms under a variety of problem conditions. To the best of our knowledge, there is no such benchmark available since most 3D benchmarks focus on one specific class of algorithms. For example, the Middlebury dataset targets MVS algorithms~\cite{seitz2006comparison}, and the `DiLiGenT' dataset targets Photometric Stereo algorithms~\cite{shi2016benchmark}. This makes such benchmarks only suitable for evaluation of within-category algorithms. Besides, there is few dataset with objects that cover a range of problem conditions. The reason for the lack of such a dataset is that it is practically impossible to create multiple versions of the same object with one property, \eg surface texture, material, and so on, varied while everything else is kept constant. In response to this challenge, we created a synthetic dataset using the physical-based rendering engine of Blender to evaluate the 3D reconstruction algorithms. Our dataset includes a collection of images of a scene under different materials and lighting conditions. The camera/projector's intrinsic and extrinsic parameters are computed directly from the configurations of the synthetic setup, and the ground truth, including the 3D model point cloud and normal map, are generated directly from Blender.

The second challenge is: the problem space is an $N-$dimensional space, consisting of $N$ properties, each with $L$ levels, thus the total number of combinations is $L^N$, which is too vast of a space to cope with. To make the problem space more tacklable, we adopt the three-point scale, where $L=3$ (Low = 0.2, Medium = 0.5, and High = 0.8). Further, We conduct $\binom{N}{2}$ $L\times L$ factorial studies to determine the properties that have a significant effect on performance of the algorithms. We can then reduce the space dimensionality by considering only these effective properties. Effective properties of an algorithm are those that have a main effect or interaction effect, or both on the performance of this specific algorithm. We illustrate the performance of algorithms under varied conditions as heatmaps so that the main effects and interactions between properties can be easily detected.

The chapter is organized as follows: section~\ref{sec:create_synth_dataset} discuss the selected algorithms, and the process of creating a synthetic dataset for the evaluation of selected algorithms. Section~\ref{sec:prop_effect_interaction} discusses the procedure of identifying properties with a significant effect on algorithmic performance so that the problem space can become more manageable. Section~\ref{sec:lookup_table} presents the lookup tables, represented by heatmaps, from problem conditions to performance of algorithms, which is served as mapping from problem condition to algorithms.

\section{Construction of Dataset}
\label{sec:create_synth_dataset}
This section discusses the construction of a synthetic dataset that is used to evaluate between-class algorithms under varied problem conditions. First we choose three representative algorithms from three distinct algorithm classes, as well as two baseline methods. Then the setups of synthetic capturing systems are presented with example images. Lastly, quantitative measure used to evaluate the performance of algorithms are proposed.

\subsection{Selected and baseline methods}
We have selected one representative algorithm from three major classes of algorithms presented in Chapter~\ref{ch:3DRecon_ProbSpace}: the PMVS proposed in~\cite{furukawa2010accurate}, the example-based Photometric Stereo proposed in~\cite{hertzmann2005example}, and the Gray-code Structured Light technique. See Table~\ref{tab:selected_algos} for a summary of the selected algorithms. The current implementation of SL projects both column and row patterns, and depth values are computed using these two kinds of patterns individually. A depth consistency step is performed to reject erroneous triangulations.
\begin{table}[!htbp]
\centering
\begin{tabular}{l|l}
\toprule
Technique & Summary\\
\midrule
PMVS & Patch-based, seed points propagation MVS.\\
EPS & Example-based Photometric Stereo.\\
GSL & Gray code Structured Light technique.\\
\midrule
VH & Volumetric Visual Hull.\\
LLS-PS & Linear least squares Photometric Stereo.\\
\bottomrule
\end{tabular}
\caption{Summary of the selected and baseline algorithms for the interface.}
\label{tab:selected_algos}
\end{table}

% \section{Baseline}
% \begin{table}[!htbp]
% \centering
% \begin{tabular}{c|c|c|c|c}
% \toprule
% Technique & Texture & Albedeo & Specular & Roughness\\
% \midrule
% \multicolumn{5}{l}{VH: volumetric Visual Hull}\\
% \midrule
% VH & - & - & - & -\\
% \midrule
% \multicolumn{5}{l}{LLS-PS: linear least squares Photometric Stereo.}\\
% \midrule
% LLS-PS & - & High & Low & High\\
% \bottomrule
% \end{tabular}
% \caption{Summary of the baseline algorithms for the framework, and the corresponding working conditions in theory.}
% \label{tab:selected_baseline_algos}
% \end{table}
We use two baseline approaches to compare our results: Visual Hull and a simple linear least squares based Photometric Stereo (LLS-PS). We use Visual Hull since it works relatively well as long as the silhouette of the object can be reliably extracted, thus being insensitive to material properties. In addition, the true scene is always enclosed by the reconstruction result, so the outcome is always predictable. We use LLS-PS to evaluate Photometric Stereo algorithms. However, there is currently no such PS algorithms that work reasonably well under a variety of conditions. Thus, we run this baseline algorithm under the optimal condition to ensure a best possible result.

\subsection{Synthetic setups}
We use the physical-based rendering engine of Blender, Cycles, to generate the synthetic datasets. For each technique, the configuration of the camera remains fixed. The image resolution is 1280$\times$720, with a focal length of $35mm$ or $1400pix$. The synthetic setups are shown in Table~\ref{tab:synth_setup}, and some example synthetic images generated using the setups are shown in Figure~\ref{fig:synth_setup}.
\begin{table}[!htbp]
\centering
\begin{tabular}{lll}
\toprule
Method & Hardwares & Arrangement\\
\midrule
MVS & 41 camera & 5 rings, each has 1, 8, 8, 12, 12 camera\\
PS & 1 camera+25 light sources & 4 rings, each has 1, 8, 8, 8, 8 light sources\\
SL & 1 camera\&projector & baseline angle: $10^\circ$\\
\bottomrule
\end{tabular}
\caption{Summary of synthetic capturing systems for three classes of algorithms.}
\label{tab:synth_setup}
\end{table}

The effects of properties simulated by the rendering engine are shown in Figure~\ref{fig:synth_example}.
\begin{figure*}[!htbp]
\centering
\begin{tabular}{ll}
Texture & \raisebox{-.5\height}{\includegraphics[width=0.8\textwidth]{img/mapping/setup/tex.png}}\\
Albedo & \raisebox{-.5\height}{\includegraphics[width=0.8\textwidth]{img/mapping/setup/alb.png}}\\
Specular & \raisebox{-.5\height}{\includegraphics[width=0.8\textwidth]{img/mapping/setup/spec.png}}\\
Roughness & \raisebox{-.5\height}{\includegraphics[width=0.8\textwidth]{img/mapping/setup/rough.png}}
\end{tabular}
\caption{Example synthetic images. The value of each property ranges from 0 to 1.}
\label{fig:synth_example}
\end{figure*}

% For the Multi-View Stereo setup, there are five rings of cameras, of which the elevation angles are $15^\circ$, $30^\circ$, $45^\circ$, $60^\circ$, $90^\circ$. The between-angles of two neighbouring cameras are $30^\circ$, $30^\circ$, $45^\circ$, $45^\circ$, and $360^\circ$. Thus, there are in total $12+12+8+8+1=41$ cameras.

% For the Photometric Stereo setup, since increasing the number of images is only important up to a point, the experimental results showed that most algorithms reaches their optimum when 15 images are used~\cite{Berkiten:2016:ARB}. To strike a balance between algorithm performance and rendering time, we use 25 light sources, which are distributed on four rings with elevation angle of $90^\circ$, $85^\circ$, $60^\circ$, and $45^\circ$. The azimuth angle between two neighbouring light sources is $45^\circ$. Thus, the total number of images is $1+8*3=25$.

% For the Structured Light setup, the baseline angle between the camera and the projector is $10^\circ$. The resolution of the projector is $1024\times768$, thus 10 Gray code patterns are needed. To counter the effect of inter-reflection, each pattern and its inverse are projected, which descreases sensitivity to scattered light. Two additional image with lights on and off are generated to help the decoding process. Thus the total number of images is $(10+10)*2+2=42$.
% \begin{figure}[!htbp]
% \centering
% \begin{tabular}{ccc}
% \includegraphics[width=0.3\textwidth]{mapping/setup/mvs_setup} &
% \includegraphics[width=0.3\textwidth]{mapping/setup/ps_setup} &
% \includegraphics[width=0.3\textwidth]{mapping/setup/sl_setup}\\
% MVS & PS & SL\\
% \end{tabular}
% \caption{Setups of the syntheic dataset}
% \label{fig:setup}
% \end{figure}

% \section{Structure of Datasets}
% All synthetic datasets used in this thesis share the similar structure, as shown in Figure~\ref{fig:dataset_structure}. \textit{Prop Comb} represents one combination of properties, which consists of no less than two properties. For instance, \textit{texture and albedo}, or \textit{albedo, and specularity}. Note that the diretory structure of PS and SL is the same as that of MVS.
% Due to the number of properties and levels for each property, it would be unrealistic to render all their combinations. For instance, if there are $N$ properties and each is discretized into $L$ levels, the number of different combinations is $L^N$, and for each combination, there are in total $41+25+42=108$ images to render. Therefore, we take another approach: 1) we investigate the \textit{effective problem domain} which consists of only the \textit{effective} and \textit{dependent} properties; 2) we generate synthetic images for the \textit{effective} and \textit{dependent} properties and all of their combinations. The structure of the dataset is as follows:
% \begin{figure}[!htbp]
% \centering
% \includegraphics[width=0.6\textwidth]{mapping/dataset_structure}
% \caption{Structure of the synthetic dataset.}
% \label{fig:dataset_structure}
% \end{figure}

\subsection{Quantitative measures}
We use the metrics proposed in \cite{seitz2006comparison} to evaluate MVS and SL algorithms. More specifically, we compute the accuracy and completeness of the reconstruction. For accuracy, the distance between the points in the reconstruction $R$ and the nearest points on ground truth $G$ is computed, and the distance $d$ such that $X\%$ of the points on $R$ are within distance $d$ of $G$ is considered as accuracy. A reasonable $d$ value is between $[3, 5]mm$, and $X$ is set as $95$. The lower the accuracy value, the better the reconstruction result. For completeness, we compute the distance from $G$ to $R$. Intuitively, points on $G$ are not ``covered'' if no suitable nearest points on $R$ are found. A more practical approach computes the fraction of points of $G$ that are within an allowable distance $d$ of $R$. Note that as the accuracy improves, the ``accuracy value'' goes down, whereas as the completeness improves, the ``completeness value'' goes up.

For photometric stereo, depth information is lost since only one viewpoint is used. Thus, the previous metrics are not applicable. Here we employ another evaluation criteria that is widely adopted, which is based on the statistics of angular error. For each pixel, the angular error is calculated as the angle between the estimated and ground truth normal, \ie $arccos$($n_g^T n$), where $n_g$ and $n$ are the ground truth and estimated normals respectively. In addition to the mean angular error, we also calculate the standard deviation, minimum, maximum, median, first quartile, and third quartile of angular errors for each estimated normal map.

% \subsection{Criteria}
% We compare the quantitative measures of a result to those of the baseline method to determine if it is a successful reconstruction. The following rules determines if a specific algorithm returns a successful reconstruction.

% For results of MVS and SL, we use both accuracy and completeness to determine if a result is successful. However, methods that return accurate results do not necessarily produce complete results. Thus, we consider a result successful if the accuracy is better while completeness is comparable to that of the baseline.

% For results of PS algorithms, we use the central value, variation, and skewness of angular error to determine if a result if successful. The rationale is explained below:

% \subsubsection{Measures of Central Tendency}
% Mean and median are both valid measures of central tendency, but as the skewness increases, the mean is dragged in the direction of the skew. As a result, the median is generally considered to be a better representative of the central location of the data. The more skewed the distribution, the greater the difference between the median and mean, and the greater the emphasis should be placed on using the median as opposed to the mean.

% \subsubsection{Variation}
% The variation of the angular error is measured by both \textit{interquatile range} ($Q_3 - Q_1$) and \textit{standard deviation} ($std$).
  
% \subsubsection{Skewness (right/positive-skewness)}
% The normal estimation becomes worse as the difference between mean and median increases. This can be explained as follows: assuming the angular error follows a Gaussian distrubtion, then mean and median are close when the normals are reliably estimated. However, if normals are poorly recovered, the mean would increase since larger angular errors exist, while the median would change far less since only a small amount of pixels are poorly estimated. Thus, the difference between mean and median is a good indicator of the quality of normal estimation.

\section{Main effects and interactions of properties}
\label{sec:prop_effect_interaction}
The greatest challenge in constructing a mapping from problem space to algorithms is the large variations in shapes and material properties, which results in a problem space that is too large to cope with. Suppose there are $N$ properties, each with $L$ discrete levels, then there are in total $L^N$ different problem conditions. Thus, the first step, discussed in Section~\ref{sec:mvs_epd},~\ref{sec:ps_epd},~\ref{sec:sl_epd}, is to reduce the dimensions of problem space by discovering the properties that have effects on performance of algorithms.

This study is a $3\times 3$ factorial design with two properties (factors), each with three levels, \ie low (0.2), medium (0.5), and high (0.8), see Table~\ref{tab:pairwise_prob_cond}. We are interested in one-way interaction (\textit{main effect}) and two-way interaction of the properties (factors).  A \textit{main effect} is the effect of one of the independent variables on the dependent variable, ignoring the effects of all other independent variables. An \textit{interaction} occurs when the effect of one independent variable on the dependent variable changes depending on the level of another independent variable. In our current design, this is equivalent to asking whether the effect of property $i$ changes depending on property $j$, where $i\neq j, i, j\in\{1, 2, 3, 4\}$. The easiest way to communicate an interaction is to discuss it in terms of the \textit{simple main effects}, which is defined as the main effect of one independent variable (e.g., property $i$) at each level of another independent variable (e.g., property $j$). We observe an interaction between two factors whenever the simple effects of one change as the levels of the other factor are changed. Assume that the error variance is small, so that differences in performance that are apparent on the graph are also statistically significant. Thus, we choose to interpret the main effects and interactions through graphs. There is a main effect of a property if there is color variation along the corresponding axis. If color changes monotonically along the diagonal, then there is no interaction between the two properties, otherwise, there is an interaction effect.
\begin{table}[!htbp]
\centering
\begin{tabular}{cc|c|c|c|}
\cline{3-5}
& & \multicolumn{3}{ c| }{Property $i$} \\ \cline{3-5}
& & 0.2 & 0.5 & 0.8 \\ \cline{1-5}
\multicolumn{1}{ |c  }{\multirow{3}{*}{Property $j$} } &
\multicolumn{1}{ |c| }{0.2} &  &  &     \\ \cline{2-5}
\multicolumn{1}{ |c  }{}                        	   &
\multicolumn{1}{ |c| }{0.5} &  &  &     \\ \cline{2-5}
\multicolumn{1}{ |c  }{}                        	   &
\multicolumn{1}{ |c| }{0.8} &  &  &     \\ \cline{1-5}
\end{tabular}
\caption{This is a $3\times 3$ factorial design. Every two properties are selected to test the main effects and interaction, there are in total $\binom{N}{2}$ combinations.}
\label{tab:pairwise_prob_cond}
\end{table}

\subsection{Main effects and interactions: PMVS}
\label{sec:mvs_epd}
We study the main effects and interaction effects of properties on the performance of PMVS in terms of accuracy and completeness. The performance of the algorithm is visualized in Figure~\ref{fig:mvs_pairwise}.
\begin{figure}[!htbp]
\begin{tabular}{cc}
\includegraphics[width=0.45\textwidth]{mapping/pairwise/mvs_tex_alb} &
\includegraphics[width=0.45\textwidth]{mapping/pairwise/mvs_tex_spec}\\
(a). Texture and albedo & (b). Texture and specularity\\\\
\includegraphics[width=0.45\textwidth]{mapping/pairwise/mvs_tex_rough} &
\includegraphics[width=0.45\textwidth]{mapping/pairwise/mvs_alb_spec}\\
(c). Texture and roughness & (d). Albedo and specularity\\\\
\includegraphics[width=0.45\textwidth]{mapping/pairwise/mvs_alb_rough} &
\includegraphics[width=0.45\textwidth]{mapping/pairwise/mvs_spec_rough}\\
(e). Albedo and roughness & (f). Specularity and roughness\\
\end{tabular}
\caption{Performance of PMVS under four problem conditions. For instance, (a) shows the performance under the condition of changing \textit{texture} and \textit{albedo} levels, while the others are fixed. The main effect of a property is illustrated by the color variation along the corresponding axis. The monotonic color variation diagonally indicates no interaction between the two properties, otherwise, there is an interaction effect. Thus in (a), we observe a main effect of texture on completeness, no other main effects and interaction effects are present.}
\label{fig:mvs_pairwise}
\end{figure}

\textbf{(a) Texture and Albedo} 
The main effects of texture and albedo on accuracy, and the main effect of albedo on completeness are not significant whereas the main effect of texture on completeness is significant such that surfaces with higher texture leads to results of higher completeness than less textured surfaces. There is not significant interaction effect between texture and albedo on either accuracy or completeness.

\textbf{(b) Texture and Specularity} 
The main effects of texture and specularity on both accuracy and completeness are significant such that surfaces with lower texture or surfaces with higher specularity leads to higher accuracy value. However, we argue that this main effect are caused by the interaction effect between texture and specularity. As we can see, the effect of specularity on both accuracy and completeness are less noticeable for lowly and highly textured surfaces whereas the effect of specularity is most substantial for surfaces with medium texture. This effect can be explained as follows: the specular lobe can only be observed by cameras positioned and oriented towards the specular lobe, such as camera $V_2$ shown in Figure~\ref{fig:mvs_spec} (a) and (c). Cameras positioned otherwise would observe the true surface, such as camera $V_1$ shown in Figure~\ref{fig:mvs_spec} (a) and (b). The algorithm would then exploit the texture information provided by views like $V_1$, and thus would be able to reconstruct a specular surface.
\begin{figure}[!htbp]
\begin{tabular}{ccc}
\includegraphics[width=0.3\textwidth]{mapping/mvs_spec/mvs_spec}&
\includegraphics[width=0.3\textwidth]{mapping/mvs_spec/mvs_spec_01}&
\includegraphics[width=0.3\textwidth]{mapping/mvs_spec/mvs_spec_00}\\
(a) Image formation & (b) $V_1$ & (c) $V_2$\\
\end{tabular}
\caption{(a) shows the reflection of light off a specular surface. $V_1$ received the diffuse component while $V_2$ receives the specular component. (b), (c) shows the images observed from these two views. The specular area (red circle) observed in $V_2$ is visible in $V_1$.}
\label{fig:mvs_spec}
\end{figure}

\textbf{(c) Texture and Roughness} 
The main effects of texture and roughness, and that of roughness on completeness are not significant whereas the main effect of texture on completeness is significant such that surfaces with higher textures leads to results with higher completeness. There is no significant interaction effect between texture and roughness on either accuracy or completeness.

\textbf{(d) Albedo and Specularity} 
The main effects of albedo and specularity on accuracy is not significant whereas the main effects of albedo and specularity on completeness are significant such that surfaces with higher albedo or lower specularity leads to higher completeness. There is no significant interaction effect between albedo and specularity in terms of accuracy and completeness as the value varies monotonically along the diagonal.

% albedo has a positive effect whereas specular has a negative effect on the reconstruction. Furthermore, the positive effect of albedo is more significant on a higher specular surface while the negative effect of specular is far more substantial on a lower albedo surface. This can be explained as follows: according to the energy conservation law, as the specular component increases, the diffuse component decreases, resulting in a less discernible diffuse area. See Figure~\ref{fig:mvs_alb_spec} (a)-(c). Increasing the diffuse albedo can counteract the effect of specularity and make the texture visible again. See Figure~\ref{fig:mvs_alb_spec} (d)-(f).
% \begin{figure}[!htbp]
% \centering
% \begin{tabular}{ccc}
% \includegraphics[width=0.33\textwidth]{mapping/mvs_alb_spec/alb_spec_0202}&
% \includegraphics[width=0.33\textwidth]{mapping/mvs_alb_spec/alb_spec_0205}&
% \includegraphics[width=0.33\textwidth]{mapping/mvs_alb_spec/alb_spec_0208}\\
% (a) spec: 0.2 & (b) spec: 0.5 & (c) spec: 0.8\\
% \includegraphics[width=0.33\textwidth]{mapping/mvs_alb_spec/alb_spec_0202}&
% \includegraphics[width=0.33\textwidth]{mapping/mvs_alb_spec/alb_spec_0502}&
% \includegraphics[width=0.33\textwidth]{mapping/mvs_alb_spec/alb_spec_0802}\\
% (d) alb: 0.2 & (e) alb: 0.5 & (f) alb: 0.8\\
% \end{tabular}
% \caption{(a)-(c). The albedo is set as 0.2, (d)-(f). The specularity is set as 0.2. According to energy conservation, as the specular component increases, the diffuse component decreases.}
% \label{fig:mvs_alb_spec}
% \end{figure}

\textbf{(e) Albedo and Roughness}
The main effects of albedo and roughness on accuracy and completeness are not significant. There is no interaction effect between albedo and roughness on either accuracy or completeness.

\textbf{(f) Specularity and Roughness} 
The main effects of specularity and roughness on accuracy and completeness are not significant. There is no interaction effect between spcularity and roughness on either accuracy or completeness.

% surface roughness can effectively diminish the specular component and make the surface appear more diffuse. Thus, in theory, roughness should have a positive impact on the reconstruction. However, since specularity is only effective on surface with medium level texture, see Figure~\ref{fig:mvs_pairwise} (b), then roughness is only effective in this case as well. Further, since higher specular, high roughness surfaces visually resemble lower specular surfaces, and achieve similar reconstruction results as well, it makes sense to incorporate the effect of roughness to specularity, and omit roughness for simplicity.

\subsubsection{Summary: PMVS}
For accuracy, specularity has a main effect such that higher specularity leads to higher accuracy value. There are no main effects for other properties. There is a significant effect between texture and specularity such that the effect of specularity is most substantial on surfaces with medium texture. There is also a significant interaction effect between albedo and specularity such that specularity is most substantial on surfaces with low albedo value.

For completeness, there is a significant main effect from texture, and no other main effects observed. There is a significant interaction effects between texture and specularity on completeness such that the negative effect of specularity is most significant on surfaces with medium level texture. There are no other significant interaction effects observed.

% The effective properties of PMVS are: texture, albedo, and specular, as shown in Table~\ref{tab:mvs_depend_prop}. Interestingly, we discovered that specularity has a more substantially negative impact on less textured, lower albedo surfaces. For instance, high specularity does not have a severely negative impact on highly textured surfaces.

\subsection{Main effects and interactions: EPS}
\label{sec:ps_epd}
We study the main effects and interaction effects of properties on the performance of EPS in terms of mean and standard deviation (SD) of angular error. The performance of the algorithm is visualized in Figure~\ref{fig:ps_pairwise}.
\begin{figure}[!htbp]
\begin{tabular}{cc}
\includegraphics[width=0.45\textwidth]{mapping/pairwise/ps_tex_alb}&
\includegraphics[width=0.45\textwidth]{mapping/pairwise/ps_tex_spec}\\
(a). Texture and albedo & (b). Texture and specularity\\\\
\includegraphics[width=0.45\textwidth]{mapping/pairwise/ps_tex_rough}&
\includegraphics[width=0.45\textwidth]{mapping/pairwise/ps_alb_spec}\\
(c). Texture and roughness & (d). Albedo and specularity\\\\
\includegraphics[width=0.45\textwidth]{mapping/pairwise/ps_alb_rough}&
\includegraphics[width=0.45\textwidth]{mapping/pairwise/ps_spec_rough}\\
(e). Albedo and roughness & (f). Specularity and roughness\\
\end{tabular}
\caption{Performance of Example-based PS under six problem conditions. For instance, (a) shows the performance under the condition of changing \textit{texture} and \textit{albedo} levels, while the others are fixed. The main effect of a property is illustrated by the color variation along the corresponding axis. The monotonic color variation diagonally indicates no interaction between the two properties, otherwise, there is an interaction effect. Thus in (a), we observe a main effect of albedo on mean angular error, no other main effects and interaction effects are present.}
\label{fig:ps_pairwise}
\end{figure}

\textbf{(a) Texture and Albedo} 
The main effects of texture on mean and SD of angular error, and the main effect of albedo on SD of angular error are not significant. The main effect of albedo on mean value of angular error is significant such that the angular error decreases as the albedo increases. There is no significant interaction effect between texture and albedo on mean and SD of angular error.

\textbf{(b) Texture and Specularity} 
The main effects of texture on mean and SD of angular error are not significant whereas the main effects of speculairty are significant such that both values increases as specularity increases. There is no significant interaction effect between texture and specularity in terms of mean and SD of angular error.
% \begin{figure}[!htbp]
% \centering
% \begin{tabular}{c|ccc}
% Image & Normal map & Height map & Angular error\\
% \hline\\
% \includegraphics[width=0.33\textwidth]{mapping/ps_tex_spec/0502_0001}&
% \includegraphics[width=0.33\textwidth]{mapping/ps_tex_spec/0502_normal}&
% \includegraphics[width=0.25\textwidth]{mapping/ps_tex_spec/0502_dmap}&
% \includegraphics[width=0.06\textwidth]{mapping/ps_tex_spec/0502_ang_error}\\
%  & spec: 0.2 & \\
% \includegraphics[width=0.33\textwidth]{mapping/ps_tex_spec/0505_0001}&
% \includegraphics[width=0.33\textwidth]{mapping/ps_tex_spec/0505_normal}&
% \includegraphics[width=0.25\textwidth]{mapping/ps_tex_spec/0505_dmap}&
% \includegraphics[width=0.06\textwidth]{mapping/ps_tex_spec/0505_ang_error}\\
%  & spec: 0.5 & \\
% \includegraphics[width=0.33\textwidth]{mapping/ps_tex_spec/0508_0001}&
% \includegraphics[width=0.33\textwidth]{mapping/ps_tex_spec/0508_normal}&
% \includegraphics[width=0.25\textwidth]{mapping/ps_tex_spec/0508_dmap}&
% \includegraphics[width=0.06\textwidth]{mapping/ps_tex_spec/0508_ang_error}\\
%  & spec: 0.8 & \\
% \end{tabular}
% \caption{(a)-(c). The texture is set as 0.5. The estimated normal map and recovered surface becomes consistently worse as the specular level rises, which is consistent with the quantitative results from Figure~\ref{fig:ps_pairwise} (b).}
% \label{fig:ps_tex_spec}
% \end{figure}

\textbf{(c) Texture and Roughness} 
The main effects of texture on mean and SD of angular error, and the main effect of roughness on SD of angular error are not significant whereas the main effect of roughness on mean of angular error is significant such that the mean angular error decreases as roughness increases. There is no interaction between texture and roughness in terms of mean and SD of angular error.

\textbf{(d) Albedo and Specularity} 
The main effects of albedo and specularity on mean and SD of angular error are significant such that the mean and angular error decrease as albedo increases or specularity decreases. There is also a significant interaction effect between albedo and specularity such that the effect of specularity on mean and SD of angular error is most significant when the surface albedo is low.
% the albedo has a positive impact on normal estimation (see Figure~\ref{fig:ps_alb_spec} (a)-(c)), whereas the specularity has a negative impact on normal estimation (see Figure~\ref{fig:ps_alb_spec} (d)-(f)).
% \begin{figure}[!htbp]
% \centering
% \begin{tabular}{c|ccc}
% Image & Normal map & Height map & Angular error\\
% \hline\\
% % \includegraphics[width=0.33\textwidth]{mapping/ps_alb_spec/0202_0001}&
% % \includegraphics[width=0.33\textwidth]{mapping/ps_alb_spec/0202_normal}&
% % \includegraphics[width=0.25\textwidth]{mapping/ps_alb_spec/0202_dmap}&
% % \includegraphics[width=0.06\textwidth]{mapping/ps_alb_spec/0202_ang_error}\\
% %  & (a) albedo: 0.2, spec: 0.2 & \\
% \includegraphics[width=0.33\textwidth]{mapping/ps_alb_spec/0802_0001}&
% \includegraphics[width=0.33\textwidth]{mapping/ps_alb_spec/0802_normal}&
% \includegraphics[width=0.25\textwidth]{mapping/ps_alb_spec/0802_dmap}&
% \includegraphics[width=0.06\textwidth]{mapping/ps_alb_spec/0802_ang_error}\\
%  & (a) albedo: 0.8, spec: 0.2 & \\
% \includegraphics[width=0.33\textwidth]{mapping/ps_alb_spec/0502_0001}&
% \includegraphics[width=0.33\textwidth]{mapping/ps_alb_spec/0502_normal}&
% \includegraphics[width=0.25\textwidth]{mapping/ps_alb_spec/0502_dmap}&
% \includegraphics[width=0.06\textwidth]{mapping/ps_alb_spec/0502_ang_error}\\
%  & (b) albedo: 0.5, spec: 0.2 & \\
% \includegraphics[width=0.33\textwidth]{mapping/ps_alb_spec/0202_0001}&
% \includegraphics[width=0.33\textwidth]{mapping/ps_alb_spec/0202_normal}&
% \includegraphics[width=0.25\textwidth]{mapping/ps_alb_spec/0202_dmap}&
% \includegraphics[width=0.06\textwidth]{mapping/ps_alb_spec/0202_ang_error}\\
%  & (c) albedo: 0.2, spec: 0.2 & \\
% \includegraphics[width=0.33\textwidth]{mapping/ps_alb_spec/0205_0001}&
% \includegraphics[width=0.33\textwidth]{mapping/ps_alb_spec/0205_normal}&
% \includegraphics[width=0.25\textwidth]{mapping/ps_alb_spec/0205_dmap}&
% \includegraphics[width=0.06\textwidth]{mapping/ps_alb_spec/0205_ang_error}\\
%  & (d) albedo: 0.2, spec: 0.5 & \\
% \includegraphics[width=0.33\textwidth]{mapping/ps_alb_spec/0208_0001}&
% \includegraphics[width=0.33\textwidth]{mapping/ps_alb_spec/0208_normal}&
% \includegraphics[width=0.25\textwidth]{mapping/ps_alb_spec/0208_dmap}&
% \includegraphics[width=0.06\textwidth]{mapping/ps_alb_spec/0208_ang_error}\\
%  & (e) albedo: 0.2, spec: 0.8 & \\
% \end{tabular}
% \caption{According to energy conservation, as the specular component increases, the diffuse component decreases. (a)-(c): the estimated normal map and recovered height map become consistently worse as the albedo decreases; (c)-(e): the estimated normal map and recovered height map become consistently worse as the specularity increases.}
% \label{fig:ps_alb_spec}
% \end{figure}

\textbf{(e) Albedo and Roughness} 
The main effects of albedo and roughness on mean of angular error are significant such that the mean angular error decreases as the albedo or roughness increases whereas the main effects on SD of angular error are not significant. There is no significant interaction effect between albedo and roughness.

\textbf{(f) Specularity and Roughness} 
The main effect of specularity on mean and SD of angular error is significant such that the values vary as the specularity changes. There is an interaction effect between specularity and roughness. More specifically, the mean and SD of angular error do not decrease monotonically as the roughness increases. More specifically, the angular error becomes worse for surfaces with medium roughness, which is counter-intuitive at first sight. However, we argue that this is because the roughness is not strong enough to counteract the specular highlights, causing a smoothed and blurred specular region with larger area, thus leading to a poorer normal estimation. See Figure~\ref{fig:ps_spec_rough} for visual illustrations.
\begin{figure}[!htbp]
\centering
\begin{tabular}{cccc}
  Image & Normal map & Height map & Angular error\\
  \hline\\
  \includegraphics[width=0.2\textwidth]{mapping/ps_spec_rough/0802_0001}&
  \includegraphics[width=0.2\textwidth]{mapping/ps_spec_rough/0802_normal}&
  \includegraphics[width=0.2\textwidth]{mapping/ps_spec_rough/0802_dmap}&
  \includegraphics[width=0.07\textwidth]{mapping/ps_spec_rough/0802_ang_error}\\
  \multicolumn{4}{c}{(a). roughness: 0.2}\\
  \includegraphics[width=0.2\textwidth]{mapping/ps_spec_rough/0805_0001}&
  \includegraphics[width=0.2\textwidth]{mapping/ps_spec_rough/0805_normal}&
  \includegraphics[width=0.2\textwidth]{mapping/ps_spec_rough/0805_dmap}&
  \includegraphics[width=0.07\textwidth]{mapping/ps_spec_rough/0805_ang_error}\\
  \multicolumn{4}{c}{(b). roughness: 0.5}\\
  \includegraphics[width=0.2\textwidth]{mapping/ps_spec_rough/0808_0001}&
  \includegraphics[width=0.2\textwidth]{mapping/ps_spec_rough/0808_normal}&
  \includegraphics[width=0.2\textwidth]{mapping/ps_spec_rough/0808_dmap}&
  \includegraphics[width=0.07\textwidth]{mapping/ps_spec_rough/0808_ang_error}\\
  \multicolumn{4}{c}{(c). roughness: 0.8}\\
\end{tabular}
\caption{An example illustrates the effect of roughness on PS. Albedo is set as 0.8, and specular is set as 0.8. The first column shows the input images, the second column shows the estimated normal map, the third column shows the integrated surface, and last column shows the angular error. We can see from the qualitative results (normal map and height map), and quantitative result (angular error) that a medium level roughness would lead to a worse normal estimation since it blurs the specular lobe.}
\label{fig:ps_spec_rough}
\end{figure}

\subsubsection{Summary: EPS} 
Albedo, specularity, and roughness all have a main effect on angular error. More specifically, higher albedo and roughness lead to lower mean angular error, higher specularity leads to higher mean and SD angular error. There is a significant interaction effect between albedo and specularity such that the effect of specularity is most significant on low albedo surfaces. There is also an interaction between specularity and roughenss such that surfaces with medium roughness lead to higher angular error compared to surface with low or high roughness.

% The properties that have an impact on EPS are: albedo, specularity, and roughness, as shown in Table~\ref{tab:ps_depend_prop}. Interestingly, we have discovered that medium level roughness can have a negative impact on normal estimation by blur the specular lobe, as shown in Figure~\ref{fig:ps_spec_rough}.
% \begin{table}[!htbp]
%   \centering
%   \begin{tabular}{l*{5}{c}}
%   \hline
%   \textbf{Metric} & Texture & Albedo & Specular & Roughness\\
%   \hline
%   Angle difference & \ding{55} & \checkmark & \checkmark & \checkmark\\
%   \hline
%   \end{tabular}
%   \caption{The \textit{effective problem domain} of EPS in terms of the \textit{angular error}.}
%   \label{tab:ps_depend_prop}
% \end{table}

\subsection{Main effects and interactions: GSL}
\label{sec:sl_epd}
We interpret the main effects and interactions of properties on the performance of GSL in terms of accuracy and completeness. The performance of the algorithm is visualized in Figure~\ref{fig:sl_pairwise}.
\begin{figure}[!htbp]
\begin{tabular}{cc}
\includegraphics[width=0.45\textwidth]{mapping/pairwise/sl_tex_alb}&
\includegraphics[width=0.45\textwidth]{mapping/pairwise/sl_tex_spec}\\
(a). Texture and albedo & (b). Texture and specularity \\\\
\includegraphics[width=0.45\textwidth]{mapping/pairwise/sl_tex_rough}&
\includegraphics[width=0.45\textwidth]{mapping/pairwise/sl_alb_spec}\\
(c). Texture and roughness & (d). Albedo and specularity \\\\
\includegraphics[width=0.45\textwidth]{mapping/pairwise/sl_alb_rough}&
\includegraphics[width=0.45\textwidth]{mapping/pairwise/sl_spec_rough}\\
(e). Albedo and roughness & (f). Specularity and roughness\\
\end{tabular}
\caption{Performance of Gray-coded SL under six problem conditions. For instance, (a) shows the performance under the condition of changing \textit{texture} and \textit{albedo} levels, while the others are fixed. The main effect of a property is illustrated by the color variation along the corresponding axis. The monotonic color variation diagonally indicates no interaction between the two properties, otherwise, there is an interaction effect. Thus in (a), we observe a main effect of albedo on completeness, no other main effects and interaction effects are present.}
\label{fig:sl_pairwise}
\end{figure}

\textbf{(a) Texture and Albedo} 
The main effect of texture on accuracy and completeness and the main effect of albedo on accuracy are not significant. The main effect of albedo on completeness is significant such that the results increases as the albedo increases. There is no significant interaction effect between texture and albedo in terms of accuracy and completeness.

\textbf{(b) Texture and Specularity} 
The main effect of texture on accuracy and completeness and the main effect of specularity on accuracy are not significant. The main effect of specularity on completeness is significant such that the results decreases as the specularity increases. There is no significant interaction effect between texture and specularity in terms of accuracy and completeness.

\textbf{(c) Texture and Roughness} 
The main effect of texture on accuracy and completeness and the main effect of roughness on accuracy is not significant. The main effect of roughness on completeness is significant such that the results increases as the roughness increases. There is no significant interaction effect between texture and roughness in terms of accuracy and completeness.

\textbf{(d) Albedo and Specularity} 
The main effects of albedo and specularity on accuracy are not significant whereas the main effects on completeness are significant such that the results increase as albedo increase or specularity decreases. There is no significant interaction effect between albedo and specularity in terms of accuracy and completeness.

% albedo has a positive effect (see Figure~\ref{fig:sl_alb_spec} (a)-(c)) whereas specularity has a negative effect on completeness (see Figure~\ref{fig:sl_alb_spec} (d)-(f)). Interestingly, similar to EPS, the positive effect of albedo gets more significant with higher specularity while the negative effect of specularity becomes less substantial as albedo increases (see Figure~\ref{fig:sl_pairwise} (d)). Neither property has a significant effect on accuracy.
% \begin{figure}[!htbp]
% \centering
% \begin{tabular}{ccc}
% \includegraphics[width=0.33\textwidth]{mapping/sl_alb_spec/sl_00020202}&
% \includegraphics[width=0.33\textwidth]{mapping/sl_alb_spec/sl_00050202}&
% \includegraphics[width=0.33\textwidth]{mapping/sl_alb_spec/sl_00080202}\\
% (a) albedo: 0.2 & (b) albedo: 0.5 & (c) albedo: 0.8\\
% \includegraphics[width=0.33\textwidth]{mapping/sl_alb_spec/sl_00020202}&
% \includegraphics[width=0.33\textwidth]{mapping/sl_alb_spec/sl_00020502}&
% \includegraphics[width=0.33\textwidth]{mapping/sl_alb_spec/sl_00020802}\\
% (d) specular: 0.2 & (e) specular: 0.5 & (f) specular: 0.8\\
% \end{tabular}
% \caption{(a)-(c): the specular is set as 0.2, albedo has a positive effect on completeness; (d)-(e): the albedo is set as 0.2, specular has a negative effect on completeness.}
% \label{fig:sl_alb_spec}
% \end{figure}

\textbf{(e) Albedo and Roughness} 
The main effects of albedo and roughness on accuracy, and the main effect of roughness on completeness are not significant. The main effect of albedo on completeness is significant such that the results increases as the albedo increases. There is no significant interaction effect between albedo and roughness in terms of accuracy and completeness.

\textbf{(f) Specular and Roughness} 
The main effects of specularity and roughness on accuracy are not significant whereas the main effect on completeness are significant such that the results increases as the roughness increases or specularity decreases. There is no significant interaction effect between specularity and roughness in terms of accuracy and completeness.
% specular has a negative effect (see Figure~\ref{fig:sl_spec_rough} (a)-(c)). Interestingly, the effect of roughness also resembles that of EPS, \ie medium level roughness has a negative impact on completeness (see Figure~\ref{fig:sl_spec_rough} (d)-(f)). Neither property has a significant effect on accuracy.
% \begin{figure}[!htbp]
% \centering
% \begin{tabular}{ccc}
% \includegraphics[width=0.33\textwidth]{mapping/sl_spec_rough/sl_00050202}&
% \includegraphics[width=0.33\textwidth]{mapping/sl_spec_rough/sl_00050502}&
% \includegraphics[width=0.33\textwidth]{mapping/sl_spec_rough/sl_00050802}\\
% (a) specular: 0.2 & (b) specular: 0.5 & (c) specular: 0.8\\
% \includegraphics[width=0.33\textwidth]{mapping/sl_spec_rough/sl_00050802}&
% \includegraphics[width=0.33\textwidth]{mapping/sl_spec_rough/sl_00050805}&
% \includegraphics[width=0.33\textwidth]{mapping/sl_spec_rough/sl_00050808}\\
% (d) roughness: 0.2 & (e) roughness: 0.5 & (f) roughness: 0.8\\
% \end{tabular}
% \caption{(a)-(c): the roughness is set as 0.2, and specular has a negative effect on completeness; (d)-(e): the specular is set as 0.8, roughness has a positive effect on completeness.}
% \label{fig:sl_spec_rough}
% \end{figure}

\subsubsection{Summary: GSL}
There is no main effects or interaction effects observed on the algorithm in terms of accuracy. Albedo, specularity, and roughness all have main effects on the algorithm in terms of completeness. There are no interaction effects observed.
% The properties that have an effect on the GSL are: texture, albedo, specular, as shown in Table~\ref{tab:sl_depend_prop}. The albedo has a more significant impact with lower specularity, while specularity has a more substantial impact with low albedo. Roughness can cause a blurred specular region, thus leading to decreased completeness.
% \begin{table}[!htbp]
%   \centering
%   \begin{tabular}{l*{4}{c}}
%   \hline
%   \textbf{Metric} & Texture & Albedo & Specular & Roughness\\
%   \hline
%   Accuracy & \ding{55} & \ding{55} & \ding{55} & \ding{55}\\
%   Completeness & \ding{55} & \checkmark & \checkmark & \checkmark\\
%   \hline
%   \end{tabular}
%   \caption{The \textit{effective problem domain} of GSL in terms of accuracy and completeness.}
%   \label{tab:sl_depend_prop}
% \end{table}

\section{Construction of Mapping}
\label{sec:lookup_table}
In the previous section, we have examined the performance of algorithms with two changing properties at a time. This is equivalent to examine the performance of algorithms on a $2-$dimensional plane embedded in a $N-$dimensional space. It gives us insights into which properties have significant impacts on the performance of algorithms. In this section, we examine the problem conditions consisting of only properties that have significant main or interaction effects on the algorithms. This is a much more feasible problem since only a subset of all $N$ properties have a significant effect on a specific algorithm. The result is a one-to-many mapping from problem condition to algorithms. To determine if an algorithm achieves a successful reconstruction, we compare the quantitative results to those of the baseline methods. More specifically, an algorithm is considered as a successful candidate if it achieves better reconstruction result than that of baseline methods in terms of quantitative measures, such as accuracy, completeness, and angular error. To illustrate the results, all quantitative measures of baseline methods are subtracted from those of selected algorithms, the results of which are visualized using heatmaps, as shown in Figure~\ref{fig:lookup_table}. To keep the results consistent, \ie positive value represents result better than that of baseline, we inverse the results of accuracy and angular error. Thus, higher value indicates better reconstruction, which indicates that the corresponding algorithm is a successful candidate. The mapping is essentially a look-up table that returns a list of successful algorithms given a problem condition, and these heatmap graphs can be viewed as mapping from problem condition to algorithms: given a problem condition, the users can specify a threshold value $\epsilon$, which is the minimum distance between the quantitative measures of selected algorithms and those of baseline methods. Any algorithm which is at least $\epsilon$ above the baseline methods are considered algorithms that can work reliably under the specified problem condition. By default, $\epsilon = 0$.
\begin{sidewaysfigure*}[!htbp]
\centering
\begin{tabular}{ccc}
\includegraphics[width=0.3\textwidth]{mapping/lookup_table/mvs_texture_02.eps} &
\includegraphics[width=0.3\textwidth]{mapping/lookup_table/mvs_texture_05.eps} &
\includegraphics[width=0.3\textwidth]{mapping/lookup_table/mvs_texture_08.eps}\\
\multicolumn{3}{c}{(a). Look-up table of PMVS.}\\
\includegraphics[width=0.3\textwidth]{mapping/lookup_table/ps_albedo_02.eps} &
\includegraphics[width=0.3\textwidth]{mapping/lookup_table/ps_albedo_05.eps} &
\includegraphics[width=0.3\textwidth]{mapping/lookup_table/ps_albedo_08.eps}\\
\multicolumn{3}{c}{(b). Look-up table of EPS.}\\
\includegraphics[width=0.3\textwidth]{mapping/lookup_table/sl_albedo_02.eps} &
\includegraphics[width=0.3\textwidth]{mapping/lookup_table/sl_albedo_05.eps} &
\includegraphics[width=0.3\textwidth]{mapping/lookup_table/sl_albedo_08.eps}\\
\multicolumn{3}{c}{(c). Look-up table of GSL.}
\end{tabular}
\caption{Performance of PMVS, EPS, and GSL under all problem conditions. These are look-up tables that provide information regarding the performance of selected algorithms compared to baseline methods. Once a threshold value $\epsilon$ is specified, these look-up tables can be used as mapping from problem condition to algorithms, \ie return successful algorithms given a problem condition.}
\label{fig:lookup_table}
\end{sidewaysfigure*}

\begin{table}[!htbp]
\centering
\begin{tabular}{l*{4}{c}}
\toprule
\textbf{Metric} & Texture & Albedo & Specular & Roughness\\
\midrule
Accuracy & 0.5 & 0.5 & 0.2 & -\\
\&Completeness & 0.5 & 0.8 & 0.2 & -\\
         & 0.5 & 0.8 & 0.5 & -\\
         & 0.8 & 0.2 & 0.2 & -\\
         & 0.8 & 0.5 & 0.2 & -\\
         & 0.8 & 0.8 & 0.2 & -\\
         & 0.8 & 0.5 & 0.5 & -\\
         & 0.8 & 0.8 & 0.5 & -\\
         & 0.8 & 0.5 & 0.8 & -\\
         & 0.8 & 0.8 & 0.8 & -\\
\bottomrule
\end{tabular}
\caption{The problem conditions under which PMVS works successfully in terms of the two metrics \textit{accuracy} and \textit{completeness}.}
\label{tab:mvs_training_result}
\end{table}

\begin{table}[!htbp]
\centering
\begin{tabular}{l*{4}{c}}
\hline
\textbf{Metric} & Texture & Albedo & Specular & Roughness\\
\hline
Angle difference& - & 0.2 & 0.2 & 0.8\\
                & - & 0.2 & 0.5 & 0.8\\
                & - & 0.2 & 0.8 & 0.8\\
                % & - & 0.5 & 0.2 & 0.2\\
                % & - & 0.5 & 0.2 & 0.5\\
                & - & 0.5 & 0.2 & 0.8\\
                % & - & 0.5 & 0.5 & 0.2\\
                & - & 0.5 & 0.5 & 0.8\\
                & - & 0.5 & 0.8 & 0.8\\
                & - & 0.8 & 0.2 & 0.2\\ % can be removed
                & - & 0.8 & 0.2 & 0.8\\
                & - & 0.8 & 0.5 & 0.2\\
                & - & 0.8 & 0.5 & 0.8\\
                & - & 0.8 & 0.8 & 0.2\\ % can be removed
                & - & 0.8 & 0.8 & 0.8\\
\hline
\end{tabular}
\caption{The problem conditions under which example-based PS works successfully in terms of the metric \textit{angular error}.}
\label{tab:ps_training_result}
\end{table}

\begin{table}[!htbp]
\centering
\begin{tabular}{l*{4}{c}}
\hline
\textbf{Metric} & Texture & Albedo & Specular & Roughness\\
\hline
Accuracy    & - & - & - & -\\
\hline
Completeness& - & 0.8 & 0.2 & 0.2\\
            & - & 0.8 & 0.5 & 0.2\\
            & - & 0.8 & 0.8 & 0.2\\
            & - & 0.8 & 0.2 & 0.8\\
            & - & 0.8 & 0.5 & 0.8\\
            & - & 0.8 & 0.8 & 0.8\\
\hline
\end{tabular}
\caption{The problem conditions under which Gray-code SL works successfully in terms of the two metrics \textit{accuracy} and \textit{completeness}.}
\label{tab:sl_training_result}
\end{table}

\section{Summary}
It is a non-trivial task to find a mapping from problem conditions to algorithms based on the description. By no means is the aforementioned approach the only way, or a perfect way, since it potentially has the problem of suffering from property scaling issue. Nonetheless, the factorial studies remains a valuable approach to obtain insights of the \textit{effective properties} of a specific algorithm. The development of the mapping is an on-going process. For instance, we can include more quantitative metrics such as colour accuracy, `ghost reconstruction', and so on. In order to make the mapping applicable to objects with more complex shapes, we need to consider more sophisticated geometric properties besides roughness, such as concavity, depth-discontinuity, occlusion, etc. Furthermore, the incorporation of more algorithms is another way to ensure that the problem space is well covered.