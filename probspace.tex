%% The following is a directive for TeXShop to indicate the main file
%%!TEX root = diss.tex

\chapter{A Problem Space of 3D Reconstruction}
\label{ch:3DRecon_ProbSpace}
We discussed the current landscape of 3D reconstruction in Chapter~\ref{ch:RelatedWork}. Previous research has solely focused on developing novel algorithms and software to tackle this problem. Thus, most research efforts have been devoted to improving algorithm performance in terms of accuracy, completeness, computational efficiency, or relax restrictive assumptions so that they can be applied to more general situations. However, this approach, which we call an \textit{algorithm-centred} approach, faces two challenges: 1) it provides little insight into the conditions that allow a specific algorithm to work successfully; 2) it requires domain-specific knowledge to fine tune algorithm specific parameters to optimize the performance. This knowledge is either unknown or largely empirical, with each algorithm mapped roughly to a sub-volume in the \textit{problem space} that is poorly defined, thus requires vision knowledge to fully take advantage of these algorithms. In this thesis, \textit{problem space} is defined as an $N-$dimensional space which encompasses the material and shape properties of objects, and thus the axes of which consist of characteristic material and geometric attributes (called \textit{properties}). The sub-volume of the \textit{problem space} is called \textit{problem condition(s)}. We argue below that a well-defined \textit{problem space} is a critical part of designing an interface of 3D reconstruction, and should receive more research efforts.

% We are facing such challenges due to the following reasons: 1) the problem space is poorly defined, thus there is no way of describing the problem conditions in the first place; 2) compared to developing algorithm novelties, it is generally a neglected research direction to study the problem conditions under which a specific algorithm works successfully.

We have established in Chapter~\ref{ch:RelatedWork} that most 3D vision algorithms target a limited set of problem conditions. They may work under one condition, but is highly likely to fail under others. Thus, they are unsuitable to reconstruct objects with a wide range of properties. It is crucial to have multiple algorithms, each registered to a distinct sub-volume of the \textit{problem space} in order to design an interface for 3D reconstruction problem. To achieve this goal, we need to first propose key attributes of objects as axes of this $N-$dimensional space, which lay the foundation of describing problem conditions in a consistent and rigorous manner. Next, we need to discover the relation between \textit{problem conditions} and algorithms so that we can know which algorithm performs well given a specific problem condition, which will be discussed in Chapter~\ref{ch:3DRecon_Mapping}. Recall that \textit{problem space} is an $N-$dimensional space, of which the axes are material and shape properties of objects. The reason we choose material and shape properties is that they can be visually and perceptually estimated, and are also widely used by typical 3D vision algorithms as reconstruction cues. With a well-defined \textit{problem space}, we are able to describe the characteristic properties of an object that are crucial for reconstruction. For instance, instead of describing a cup simply as a `cup', we can describe it as `a white, glossy porcelain cup with shallow strips on the surface'. The visual and geometric properties, represented by words such as `white', `glossy', and `shallow', are crucial in terms of determining which algorithm is able to perform well. We call it a \textit{problem-centred} approach. This approach transforms the 3D reconstruction problem from one requiring knowledge and expertise of specific algorithms in terms of \textit{how} to use them, to one requiring knowledge of problem conditions, which can be perceptually estimated or measured. The advantage of the \textit{problem-centred} approach are as follows: 1) the properties can be universally used by most objects, without the need of algorithm-specific parameters; 2) the properties of the \textit{problem space} can be visually or perceptually estimated. Thus, there is no need to understand the meanings of algorithm parameters, \ie no vision knowledge required.

% Note we have specifically focused on the material and geometric properties of the objects, as they are the cues used by many vision algorithms, and also the key components of the problem space. It then becomes possible to evaluate the performance of algorithms under this well-defined conditions, which generates a one-to-one relation between problem space and algorithms. 

In this chapter, we first propose a well-defined problem space consisting of visual and geometric properties of objects in Section~\ref{sec:prob_space}. Since the problem space is generally too vast to tackle, we state addition assumptions and underlying rationale to limit the scope of problem space in Section~\ref{sec:assumptions}. Finally, we propose four main problem conditions that we are interested in investigating in this thesis.

% First, we need to have a better understanding of the problem space. In this thesis, what we mean problem space is the volume of reflectance and shape variations that objects occupy. We first describe the visual and geometric properties that constitute this problem space, then we provide further discussions regarding additional assumptions and underlying rationales to further narrow the problem space, and propose the 

% Developers started to come up with applications and working scenarios that are suitable for the developed algorithms. This approach to problem solving leads to so many examples of excellent technology, yet poor applications. The scientific approach to problem solving starts with defining the problem of interest. Without a formal understanding of the problem space, any efforts towards solving the problem have the risk of getting stuck in a deadend or diverging into a totally different and irrelevant direction and ending up with an undesired solution. The same logic applies to the research on 3D reconstruction. Thus, this chapter sets out to gives a comprehensive definition to the field of 3D reconstruction, and states additional assumptions to narrow the problem space so that it can be tackle within this thesis.

\section{Problem space}
\label{sec:prob_space}
We first give an overview of problem space, which consists of visual and geometric properties of real-world objects, as shown in Figure~\ref{fig:obj_class}. These properties can be conceptualized as axes of the 3D reconstruction problem space. This approach allows us to think of algorithms as ``pointers'' to volumes within an $N-$dimensional problem space. Existing algorithms can be incorporated into the interface by evaluating the algorithm performance within the problem space, as shown in Figure~\ref{fig:embed_algo}. However, by no means is the presented problem space complete. There are many other properties not included that are commonly seen in the real world. For instance, properties such as metalness, emission, occlusion, discontinuity, among others, are not considered. However, the listed set of properties are broad enough to encompass a wide range of real-world objects. To help easy identification of a specific problem condition, we propose the following labels to differentiate object classes, as shown in Figure~\ref{fig:obj_class}.
\begin{figure}[!htbp]
\centering
\includegraphics[width=\textwidth]{probspace/obj_class}\\
\caption{A list of properties with labels of the proposed problem space.}
\label{fig:obj_class}
\end{figure}

%\begin{table}[!htbp]
%\centering
%\begin{tabular}{l | ll}
%\toprule
%Property name & Property value & Property label \\
%\midrule
%\multirow{3}{*}{Translucency} & Opaque & \textbf{O} \\
%							  & Translucent & \textbf{Tl} \\
%							  & Transparent & \textbf{Tp} \\ \cline{2-3}
%\multirow{3}{*}{Texture} & Textured & \textbf{T} \\
%						 & Repeated textured & \textbf{Tr} \\
%						 & Textureless & \textbf{Tl} \\ \cline{2-3}
%\multirow{2}{*}{Brightness} & Bright & \textbf{B} \\
%						    & Dark 	& \textbf{D} \\ \cline{2-3}
%\multirow{5}{*}{Reflection} & Specular model & \textbf{S} \\
%							& Diffuse model  & \textbf{D} \\
%							& Mixed model	 & \textbf{M} \\
%							& Sub-surface scattering & \textbf{Ss} \\
%							& Refraction 	 & \textbf{Rf} \\ \cline{2-3}
%\multirow{2}{*}{Roughness} & Smooth & \textbf{S} \\
%						   & Rough 	& \textbf{R} \\ \cline{2-3}
%\multirow{2}{*}{Concavity} & Convex  & \textbf{Cx} \\
%						   & Concave & \textbf{Cv} \\
%\bottomrule
%\end{tabular}
%\caption{Labels of properties.}
%\label{tab:prop_label}
%\end{table}

\section{Assumptions}
\label{sec:assumptions}
Though 3D reconstruction of opaque surfaces with Lambertian reflectance has been a well studies problem, specular, translucent, transparent, and refractive scenes still pose challenging problems for acquisition systems~\cite{ihrke2010transparent}. \citeauthor{ihrke2010transparent} conducted a comprehensive review on acquisition approaches for transparent and specular surfaces, and concluded that though different classes of techniques have been developed to deal with these problems and good reconstruction results can be achieved with current state-of-the-art techniques~\cite{ihrke2010transparent}. However, the proposed approaches are still highly specialized and targeted at a very specific object class~\cite{ihrke2010transparent}. Thus, the limits of existing techniques demands that only a subset of problem space can be solved robustly. Further, it is more feasible as a proof of concept demonstration to target a sub-space. Therefore, we make the following assumptions to the keep problem space more tractable:

\subsubsection{Simplified light-matter interaction model}
We assume \textbf{local interaction model}, \ie global light transport such as transmission, refraction, cast shadow, inter-reflection are not considered. The rationale behind our choice is that most techniques that have been developed over the past few decades mainly tackle object with an opaque, diffuse or mixed surface~\cite{ihrke2010transparent}. Since the majority of reconstruction techniques rely on observing light reflected off a surface, surfaces exhibit significant effect of global light transport present a huge challenge to the reconstruction problem. For specular, refractive, and translucent or transparent objects, only very specialized algorithms are applicable for reconstruction~\cite{ihrke2010transparent}. This is a widely used and accepted model in varied areas of computer vision, including shape from stereo, shading, and so on. As more algorithms become available to tackle these types of objects, they can be embedded to the interface using the same approach that will be discussed in Chapter~\ref{ch:3DRecon_Mapping}, as shown in Figure~\ref{fig:embed_algo}.
\begin{figure*}[!htbp]
\centering
\includegraphics[width=0.8\textwidth]{img/probspace/mapping.pdf}
\caption{Embed algorithms into the interface. The process is three-fold: 1) reduce problem space by discovering \textit{effective properties} denoted by red; 2) discover mapping from the lower-dimensional problem space to algorithm, denoted by green; 3) mapping from problem space to algorithms denoted by blue.}
\label{fig:embed_algo}
\end{figure*}

\subsubsection{Simplified reflectance model}
Most real-world surfaces are not optically flat, or smooth at a microscopic scale. In most cases, there are irregularities present which are much larger than the light wavelength, but too small to be seen or resolved. The \textit{microfacet theory} assumes that the surface is composed of a large collection of \textit{microfacets}, each reflecting light from a given incoming direction into a single outgoing direction which depends on microfacet normal. We assume \text{microfacet reflectance model}, which consists of a diffuse and a specular term. The diffuse term can be approximated by a Lambertian model, and the specular term is determined by material, viewing angle, shadowing, surface geometry, and so on.

\subsubsection{Simplified geometric model}
It is a challenging task to model geometry using mathematical descriptions. For geometric primitives such as cube, sphere, or cone, etc, it's possible to describe the shape using concise descriptions. However, the task becomes more challenging when it comes to shapes with varied characteristics. Furthermore it becomes more ambiguous when natural language is employed. Thus we only consider the microscopic roughness of the surface, which has a direct relation with the reflection. Other prominent geometric properties such as \textit{concavity}, which affects self-shadow, inter-reflection, \textit{depth-discontinuity}, which affects the depth estimation, are not considered.

\subsubsection{Surface reflectance}
Existing 3D vision techniques requires distinct cues for reconstruction, be it texture, intensity variation, focus change, and so on. This information will become much noisier and less effective on darker surfaces. Surfaces with low albedo will make many algorithms ineffective, including most active techniques. In this thesis, dark surfaces could be challenging for all the underlying algorithms implemented within the interface. This works fine when it comes to design and use such an interface since there is no need for all underlying algorithms to work reliably. However, from a demonstrative standpoint, this would render the interface failing to call any of the selected algorithms except the baseline methods, which fails to demonstrate the performance of interpreter. Thus, we decided to use objects with bright surfaces so that the interpreter can invoke one of the underlying algorithms given accurate description.

\subsubsection{Setup of capturing system}
The configuration of capturing system determines the selection of algorithm in a variety of ways. The capturing device determines what type of data is captured, which could be RGB images, or range data depending on whether a camera of laser scanner is used. The lighting condition determines if a passive or active method is selected since active methods need controlled lighting. The number of vantage points determines if data from different viewpoints or under different illuminations are needed. In short, variations in the capturing systems can greatly impact which algorithm is effective, or the performance of algorithms. However, this significantly increases the complication of the problem. Thus, we decide to use a fixed capturing system throughout the thesis. However, note that the results obtained under this capturing system might not be applied to data captured using a different capturing system. However, the approach would not be affected by the hardware setup.

% \subsection{Four problem conditions}
% \label{sec:prob_cond}
Built upon the previously defined problem space, and additional assumptions, we define four classes of problem conditions that will be investigated in depth, as shown in Figure~\ref{fig:prob_cond}. We will demonstrate that it is achievable to design a description-based interface that hides algorithm details and return solutions without knowing the underlying algorithms using objects that satisfy these conditions.
\begin{figure*}[!htbp]
\centering
\includegraphics[width=0.9\textwidth]{probspace/prob_cond}
% (a). Most real-world objects do no exhibit extreme properties, such as $0\%$ or $100\%$ brightness, thus we consider the end points as extremities, and represented in grey. The area represented by green is the range of property that we are interested in; (b). 
\caption{Four problem conditions selected based on the definition of problem space and additional assumptions. The description-based interface will be evaluated using objects satisfying these conditions.}
\label{fig:prob_cond}
\end{figure*}

\subsection{Discussion and Conclusions}
Most vision research has been devoted to developing algorithm novelties and improving performance. However, the conditions under which an algorithm works reliably is often a neglected subject. However, this is a crucial part of designing a 3D reconstruction interface. Since no single algorithm can work reliably under a wide range of conditions, it is required to have multiple algorithms, each covering a distinct or partially overlapping sub-volume. The problem then becomes under which condition can an algorithm work successfully. To answer this question, we first need to define the problem space and problem conditions. Otherwise, it is a poorly-defined task to describe the problem condition of an object.

We first proposed a well-defined problem space, which is an $N-$dimensional space, the axes of which are reflective and geometric properties of objects. The problem condition(s) is then defined as a sub-volume within the problem space. Since existing 3D vision algorithms can only deal with certain classes of objects, we further proposed assumptions to limit the problem space to a more feasible range. Further, to implement a proof of concept interpreter for demonstrative purpose, we choose four problem conditions to demonstrate the proposed interpreter.

Since this thesis studies a sub-space of the entire problem space, a natural question is whether this approach extends to a broader space when incorporating properties that have been left out, such as refraction, sub-surface scattering, and so on. This is a challenging task, and depends on two aspects: 1) robust techniques that work successfully under these conditions have been developed; 2) there is a way to describe the corresponding properties. The goal of this thesis is to demonstrate whether it is possible for the proof of concept interpreter to find a reliable algorithm given a description of problem condition. Thus, this is left as a future research direction.
