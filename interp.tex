%% The following is a directive for TeXShop to indicate the main file
%%!TEX root = diss.tex

\chapter{An Interpretation of 3D Reconstruction}
\label{ch:3DRecon_Interp}
So far, we proposed a well-defined problem space for 3D reconstruction problem and a precise mapping from the problem space to the algorithm space. We need to validate that the derived mapping can be reliably applied to object with a different shape, and demonstrate the usage of the framework, \ie interpretability from the problem centric description to a reliable reconstruction result must be shown.

However, such an evaluation faces several challenges: 1). the derived mapping pose very few constraints on the types of material and geometry, thus an exhaustive evaluation would require a vast amount of objects to reach to a solid conclusion, which is not a practical approach; 2). 

% In Chapter~\ref{ch:3DRecon_Mapping}, we have established a mapping from a well defined problem space to a suite of algorithms by evaluating the performance of the selected algorithms under synthetic conditions. However, the claim that this mapping would help the users obtain a satisfactory reconstruction result given the correct problem conditions is still unclear. Thus a thorough evaluation is needed to validate the proposed framework.

Although only three algorithms selected, all of which are the top performers in the corresponding field, thus are sufficient to validate the framework's ability to translate the descriptive model into a reconstruction. The integration of new algorthms requires that they be evaluated with a the same problem conditions presented in Chapter~\ref{ch:3DRecon_Mapping}, thus allowing researchers to contribute novel algorithms to the framework once become available.

Section~\ref{sec:interp_eval_methodology} gives a the roadmap of our evaluation which is centered around two key evaluation questions: extensiveness of the mapping, and interpretability of the algorithm-free framework. Section~\ref{sec:interp_extend} investigates cases under which the mapping can be reliably applied to other objects. Section~\ref{sec:interp_useful} presents real-world use cases of the framework, where a satisfactory reconstruction result is return given the correct description of object.

% In order to validate the 3D reconstruction mapping derived from Chapter~\ref{ch:3DRecon_Mapping}, evaluation of the object centric model into appropriate solutions must be shown. Our interpreter is based on the direct evaluation of the performance of each 3D reconstruction algorithm under different conditions presented in Chapter~\ref{ch:3DRecon_Mapping}. From this analysis of how algorithms perform on objects which have different visual and geometric properties, an algorithm(s) can be definitively chosen based on which performed best on the training images.

\section{Evaluation Methodology}
\label{sec:interp_eval_methodology}
This section formulates the methodology of evaluation. We start with the objective, which gives a brief introduction of what needs to be evaluated. Then two key evaluation questions are proposed, with evaluation steps, criteria and expected outcomes to determine if the evaluation is successful.

\subsection{Objective}
% [Develop a description (or access an existing version) of what is to be evaluated and how it is understood to work.]
This evaluation intends to validate that 1) the derived mapping from Chapter~\ref{ch:3DRecon_Mapping} can be extended to objects with different shapes, and demonstrate cases where it fails; 2) demonstrate the real-world use cases of the proposed framework. For the first goal, objects with varied degrees of shape changes are used, and the corresponding results are compared to the mapping. We attempt to demonstrate if the mapping, to some extent, is invariant to the changes of shape, and when would it fail to hold. For the second goal, we use real-world objects to demonstrate that the framework can return a satisfactory result when provided with a correct description.

% \subsection{Frame}
% Set the parameters of the evaluation its purposes, key evaluation questions and the criteria and standards to be used.

% \subsubsection{Purpose}
% [What are the primary purposes and intended uses of the evaluation?]
% The evaluation intends to find out that the derived mapping can indeed find the algorithm that produces the best possible result from a suite of algorithms.

\subsection{Key Evaluation Questions and Steps}
% [What are the high level questions the evaluation will seek to answer? How can these be developed?]

The evaluation attempts to 1) \textit{prove that the mapping can be extended to other objects with different geometries}; 2). \textit{demonstrate that the framework can return a satisfactory reconstruction result given a correct description}.

\subsubsection{1. Does the mapping work for objects with a different shape?}
We first need to prove that the mapping derived in Chapter~\ref{ch:3DRecon_Mapping} is applicable to objects with different shapes. However, the variations of geometry is too vast and complicated to model, it wouldn't be possible to consider all these conditions. Thus we focus on one geometric property that in theory could have an impact on the mapping, which is the concavity of the surface. We use three synthetic objects with varied degrees of concavity, and verify if the mapping is appliable under those circumstances, and when it would fail to hold. We use synthetic data to verify the mapping since it would not be practical to change material properties using real world objects. The evaluation steps include:

% \noindent\textbf{System setup}: the synthetic data is generated by the Blender using the same setups in Chapter~\ref{ch:3DRecon_Mapping};

\noindent\textbf{Data generation}: the synthetic data is generated in the Blender using the same setups presented in Chapter~\ref{ch:3DRecon_Mapping}. We consider the four property settings representing four major classes of real-world objects in Chapter~\ref{ch:3DRecon_Taxo}.

% \noindent\textbf{Algorithm execution and evaluation}: three selected algorithms as well as the baseline are used to reconstruct the synthetic object. Quantitative and qualitative results are plotted;

% \noindent\textbf{Validation of mapping}: for each object, we verify if the reconstruction results are consistent to the mapping. If not, which algorithm is more suspectible to the change of concavity.

\noindent\textbf{Criteria}: it consists of two steps: 1). the successful algorithm in each case should be identified; 2). the reliable algorithms should be consistent with those returned from the mapping. First, we use both quantitative and qualitative results to verify that the results of the test objects are consistent with those of the mapping. To determine that a method returns a reliable result, the accuracy value should be lower than that of the baseline method while the completeness should be higher, and all the statistical measures of the angular error must be lower than those of the baseline method, including the mean, median, standard deviation, and interquatile range. The qualitative results are used to further confirm the validity of the quantitative results and give a visual sense of the . Once we have identified the successful algorithm(s) in each problem condition, we need to verify that they are consistent with those of the mapping. If that is not the case, we need to find out how robust each algorithm is with respect to concavity changes, and how concavity change affects the reconstruction results.

\subsubsection{2. Can the framework return a satisfactory recontruction given the correct description.}
Given a correct description of the object, the algorithm chosen by the mapping should give a satisfactory reconstruction result of a real-world object. However, the quantitative results are not available since we don't have the groundtruth data. Therefore, visual inspection is utilized to determine the quality of reconstruction results. The framework would use the algorithm determined by the mapping, which is then compared to the baseline algorithm to determine if the quality is acceptable. As previously mentioned, the baseline method is chosen so that it can always provide a decent reconstruction under most circumstances. The evaluation steps are presented as follows:

\noindent\textbf{Data generation}: the real-world data are captured using similar setups as the synthetic counterparts: for MVS, a Nikon D700 camera with [focal] lens are used; for photometric images, a Nikon D700 camera with [focal] lens, a handheld lamp, and two reference objects are used, a diffuse one and a glossy one; for structured light techniques, a Nikon 700 camera and a [??] projector are used, which is positioned with a bewteen angle of around $10^\circ$. We used nine everyday objects with varying texture, reflectance properties, and shape with low concavity.

\noindent\textbf{Criteria}: we need to demonstrate that: 1). the interpreter would return a reliable reconstructed model given the correct description, and a less successful one given an invalid description; 2). the algorithm chosen by the interpreter should be one of the top performers among all the algorithms implemented within the framework. The quality of the reconstruction is determined by comparing the result to the baseline method.

% \subsubsection{2. Usefulness of Mapping: How the mapping will return the result based on your description and your requirements}
% The purpose of the framework is not to compare which algorithm gives the best result, but to get the best possible reconstruction result given the correct description. Therefore, we want to see how well it works given the correct description, and how badly the result deteriorates given the incorrect description.

% The evaluation steps are:
% \begin{itemize}
% \item We chose three objects so that each algorithm would be activated by the mapping once as a demonstrative result.
% \item 
% \end{itemize}

% \subsubsection{2. Robustness: Does the mapping still return the best algorithm given an incorrect description?}
% Assume given a incorrect description of the object, will the mapping return a less satisfactory result instead, which is what it should behave like?

% \subsubsection{3. Improvement: Is the mapping more useful than the traditional approach?}
% Aside from being able to get the correct results, it's also important that the proposed approach has significant advantages over the traditional ones. We first need to identify the traditional way of employing reconstruction algorithms, find out the strengths and weakness and see if the proposed approach is superior than the exising one in the claimed aspects. The following are the aspects we set out to compare:
% \begin{itemize}
% \item is it easier?
% \item does it cater to more general object?
% \end{itemize}

% The evaluation steps are:
% \begin{itemize}
% \item Define the fundamental steps for both the traditional approach and the one proposed in the thesis.
% \item we adopt the same approach for analysing algorithmic complexity, and use basic step as the unit step to evaluate the complexity of using these two approaches. Complexity analysis is also a tool that allows us to explain how an algorithm behaves as the input grows larger. fundamental instructions/steps
% \end{itemize}

% \subsubsection{Criteria}
% Determine what `success' look like? What should be the criteria and standards for judging performance? Whose criteria and standards matter? What process should be used to develop agreement about these?

% \subsubsection{Steps}
% [Collect and retrieve data to answer descriptive questions about the activities of the project/programme/policy, the various results it has had, and the context in which it has been implemented.]

\section{Parameter Setting}
We provide results from three different descriptios where wach activates a different algorithm and provides a demonstrative result. The first step of the process is to estimate the amount of property in the object. We use a try-and-fit approach, where the user change the value of each property and see if the rendered result looks alike the real object. A similar approach can be found in the~\cite{Berkiten:2016:ARB} where the author also used a synthetic dataset to find the contributing factors of PS.
\begin{figure}[!htbp]
\centering
\begin{tabular}{cc}
  \includegraphics[width=0.4\textwidth]{interp/ui_sphere.PNG}&
  \includegraphics[width=0.4\textwidth]{interp/ui_teapot.PNG}\\
  (a) Lit sphere & (b) Lit teapot\\
\end{tabular}
\caption{The UI of determining the albedo, specular, and roughness of the surface. The albedo is set as around 0.8, which is determined by the value channel of HSV colour. The specular and roughness is set as 0.5, 0.2, respectively. (a) demonstrates the effect of the property setting on a sphere while (b) on a teapot.}
\label{fig:ui}
\end{figure}

\section{Validation of Mapping}
\label{sec:interp_extend}
We first validate that the derived mapping can be applied to object with a different shape. The idea is that given the description of an arbitrary object, we use all three techniques for reconstruction, and see if the algorithm that has the best quantitative or qualitative result is consistent to the algorithm chosen by the mapping.

It requires an understanding of algorithmic performance across difference range of problem space to create an interpreter of the 3D reconstruction problem. The synthetic dataset presented in depth in Chapter~\ref{ch:3DRecon_Mapping} provides us with a detailed understanding of how the different combinations of properties affect the performance of algorithms. This allows us to select an appropriate algorithm based on 

\subsection{Synthetic Datasets}
We use three objects with increasing degree of concavity, which are `bottle', `knight', and `king', as shown in Figure~\ref{fig:synth_data}. We select four property settings representing the four classes of most commonly seen objects discussed in Chapter~\ref{ch:3DRecon_Desc}, which is shown in Table~\ref{tab:prop_list_synth_data} to assess the validity of the mapping. We present the results of the mapping in Table~\ref{tab:prop_list_synth_data} as a reference to check if the quantitative and qualitative results from the testing data is consistent with the results of the mapping. The result is shown in Figure~\ref{fig:synth_data_results_bottle},~\ref{fig:synth_data_results_knight}, and~\ref{fig:synth_data_results_king}.
\begin{table}[!htbp]
  \centering
  \begin{tabular}{*{5}{c}|*{3}{r}}
  \hline
  & & & & & \multicolumn{3}{c}{Metrics}\\
  Class & Texture & Albedo & Specular & Roughness & Accuracy & Completeness & Ang diff\\
  \hline
  (a) & 0.2 & 0.8 & 0.2 & 0.8 & GSL & GSL & EPS\\
  (b) & 0.2 & 0.8 & 0.5 & 0.2 & GSL & - & - \\
  (c) & 0.8 & 0.8 & 0.2 & 0.8 & PMVS, GSL & PMVS, GSL & EPS \\
  (d) & 0.8 & 0.8 & 0.5 & 0.2 & PMVS, GSL & PMVS & -\\
  \hline
  \end{tabular}
  \caption{Property settings of the three testing objects: `bottle', `knight', `king', which have increasing degree of }
  \label{tab:prop_list_synth_data}
\end{table}

\begin{figure}[!htbp]
\centering
\begin{tabular}{cccc}
  \includegraphics[width=0.2\textwidth]{interp/synth_data/bottle/bottle_mvs}&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/bottle/bottle_ps}&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/bottle/bottle_sl}&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/bottle/bottle_ps_gt}\\
  \includegraphics[width=0.2\textwidth]{interp/synth_data/knight/knight_mvs}&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/knight/knight_ps}&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/knight/knight_sl}&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/knight/knight_ps_gt}\\
  \includegraphics[width=0.2\textwidth]{interp/synth_data/king/king_mvs}&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/king/king_ps}&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/king/king_sl}&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/king/king_ps_gt}\\
  MVS & PS & SL & Normal groundtruth\\
\end{tabular}
\caption{The synthetic dataset and groundtruth for the evaluation of the extensiveness of the mapping to objects with different shapes. Three objects with varied degrees of concavity are selected, each is configured with four properties settings.}
\label{fig:synth_data}
\end{figure}

% Here is the Table to test the effectiveness of the mapping
% \begin{figure}[!htbp]
% \centering
% \begin{tabular}{cccccc}
% \hline
% & & Mapping & \multicolumn{2}{c}{Accu\&Cmplt} & Norm\\
% \hline
% \multirow{2}{*}{Obj} & \multirow{2}{*}{Desc} & \multirow{2}{*}{Algo} & PMVS & Gray SL & Example PS\\
% \includegraphics[width=0.15\textwidth]{interp/synth_data/knight/knight_mvs} &
% 02080208 & EPS, GSL & 
% \includegraphics[width=0.15\textwidth]{interp/synth_data/knight/knight_mvs_02080208} &
% \includegraphics[width=0.15\textwidth]{interp/synth_data/knight/knight_ps_02080208} &
% \includegraphics[width=0.15\textwidth]{interp/synth_data/knight/knight_sl_02080208}\\
% \hline
% \end{tabular}
% \end{figure}

\subsubsection{Data 1: bottle}
The first test object is a `bottle', which has shadow groove on the surface, thus low level concavity. The synthetic object is configured with four property settings listed in Table~\ref{tab:prop_list_synth_data}. In the first column, the results of the mapping is presented. We can see that both the quantitative and qualitative results are consistent with the mapping.
\begin{sidewaysfigure}[!htbp]
\centering
\begin{tabular}{c|ccccc}
  Mapping & Quantitative results & ~ & Qualitative results & ~\\
  \hline
  EPS, GSL & 
  \includegraphics[width=0.2\textwidth]{interp/synth_data/bottle/bottle_02080208}&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/bottle/bottle_mvs_02080208.png}&
  \fcolorbox{green}{white}{\includegraphics[width=0.2\textwidth]{interp/synth_data/bottle/bottle_ps_02080208.png}}&
  \fcolorbox{green}{white}{\includegraphics[width=0.2\textwidth]{interp/synth_data/bottle/bottle_sl_02080208.png}}\\
  & \multicolumn{4}{c}{(a). tex(0.2), alb(0.8), spec(0.2), rough(0.8)}\\
  -&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/bottle/bottle_02080502}&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/bottle/bottle_mvs_02080502.png}&
  \fcolorbox{green}{white}{\includegraphics[width=0.2\textwidth]{interp/synth_data/bottle/bottle_ps_02080502.png}}&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/bottle/bottle_sl_02080502.png}\\
  & \multicolumn{4}{c}{(b). tex(0.2), alb(0.8), spec(0.5), rough(0.2)}\\
  PMVS, EPS, GSL&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/bottle/bottle_08080208}&
  \fcolorbox{green}{white}{\includegraphics[width=0.2\textwidth]{interp/synth_data/bottle/bottle_mvs_08080208.png}}&
  \fcolorbox{green}{white}{\includegraphics[width=0.2\textwidth]{interp/synth_data/bottle/bottle_ps_08080208.png}}&
  \fcolorbox{green}{white}{\includegraphics[width=0.2\textwidth]{interp/synth_data/bottle/bottle_sl_08080208.png}}\\
  & \multicolumn{4}{c}{(c). tex(0.8), alb(0.8), spec(0.2), rough(0.8)}\\
  PMVS&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/bottle/bottle_08080502}&
  \fcolorbox{green}{white}{\includegraphics[width=0.2\textwidth]{interp/synth_data/bottle/bottle_mvs_08080502.png}}&
  \fcolorbox{green}{white}{\includegraphics[width=0.2\textwidth]{interp/synth_data/bottle/bottle_ps_08080502.png}}&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/bottle/bottle_sl_08080502.png}\\
  & \multicolumn{4}{c}{(d). tex(0.8), alb(0.8), spec(0.5), rough(0.2)}\\
  \hline
  ~ & ~ & MVS & PS & SL\\
\end{tabular}
\caption{The first column shows the best algorithm chosen by the mapping. The quantitative and qualitative performance of each technique on the synthetic dataset. The red dots are from the ground truth while the black ones the reconstruction.}
\label{fig:synth_data_results_bottle}
\end{sidewaysfigure}

\subsubsection{Data 2: knight}
The second object is a chess piece: knight, which has medium concavity. In this case of medium concavity, we can see that the algorithms returned from the mapping is consistent to both the quantitative and qualitative results.

\begin{sidewaysfigure}[!htbp]
\centering
\begin{tabular}{c|ccccc}
  Mapping & Quantitative results & ~ & Qualitative results & ~\\
  \hline
  EPS, GSL & 
  \includegraphics[width=0.2\textwidth]{interp/synth_data/knight/knight_02080208}&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/knight/knight_mvs_02080208.png}&
  \fcolorbox{green}{white}{\includegraphics[width=0.2\textwidth]{interp/synth_data/knight/knight_ps_02080208.png}}&
  \fcolorbox{green}{white}{\includegraphics[width=0.2\textwidth]{interp/synth_data/knight/knight_sl_02080208.png}}\\
  & \multicolumn{4}{c}{(a). tex(0.2), alb(0.8), spec(0.2), rough(0.8)}\\
  - &
  \includegraphics[width=0.2\textwidth]{interp/synth_data/knight/knight_02080502}&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/knight/knight_mvs_02080502.png}&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/knight/knight_ps_02080502.png}&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/knight/knight_sl_02080502.png}\\
  & \multicolumn{4}{c}{(b). tex(0.2), alb(0.8), spec(0.5), rough(0.2)}\\
  PMVS, EPS, GSL&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/knight/knight_08080208}&
  \fcolorbox{green}{white}{\includegraphics[width=0.2\textwidth]{interp/synth_data/knight/knight_mvs_08080208.png}}&
  \fcolorbox{green}{white}{\includegraphics[width=0.2\textwidth]{interp/synth_data/knight/knight_ps_08080208.png}}&
  \fcolorbox{green}{white}{\includegraphics[width=0.2\textwidth]{interp/synth_data/knight/knight_sl_08080208.png}}\\
  & \multicolumn{4}{c}{(c). tex(0.8), alb(0.8), spec(0.2), rough(0.8)}\\
  PMVS&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/knight/knight_08080502}&
  \fcolorbox{green}{white}{\includegraphics[width=0.2\textwidth]{interp/synth_data/knight/knight_mvs_08080502.png}}&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/knight/knight_ps_08080502.png}&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/knight/knight_sl_08080502.png}\\
  & \multicolumn{4}{c}{(d). tex(0.8), alb(0.8), spec(0.5), rough(0.2)}\\
  \hline
  ~ & ~ & MVS & PS & SL\\
\end{tabular}
\caption{The first column shows the best algorithm chosen by the mapping. The quantitative and qualitative performance of each technique on the synthetic dataset. The red dots are from the ground truth while the black ones the reconstruction.}
\label{fig:synth_data_results_knight}
\end{sidewaysfigure}

\subsubsection{Data 3: king}
The last synthetic object is another chess piece: king, which has the largest concavity. As we can see, the quantitative results of PMVS and GSL are still consistent with that of the mapping. However, the results of the EPS is completely inconsistent, which is the result of the cast shadow effect due to the large concavity. Even though for condition (a), (c) the result of EPS is still better than that of the baseline, the medium angular error is above the acceptable threshold, which is $10^\circ$. We can see clearly from the normal maps that the cast shadow on the `crown' leads to completely inaccurate normal estimation.
\begin{sidewaysfigure}[!htbp]
\centering
\begin{tabular}{c|ccccc}
  Mapping & Quantitative results & ~ & Qualitative results & ~\\
  \hline
  GSL & 
  \includegraphics[width=0.2\textwidth]{interp/synth_data/king/king_02080208}&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/king/king_mvs_02080208.png}&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/king/king_ps_02080208.png}&
  \fcolorbox{green}{white}{\includegraphics[width=0.2\textwidth]{interp/synth_data/king/king_sl_02080208.png}}\\
  & \multicolumn{4}{c}{(a). tex(0.2), alb(0.8), spec(0.2), rough(0.8)}\\
  - &
  \includegraphics[width=0.2\textwidth]{interp/synth_data/king/king_02080502}&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/king/king_mvs_02080502.png}&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/king/king_ps_02080502.png}&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/king/king_sl_02080502.png}\\
  & \multicolumn{4}{c}{(b). tex(0.2), alb(0.8), spec(0.5), rough(0.2)}\\
  PMVS, GSL&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/king/king_08080208}&
  \fcolorbox{green}{white}{\includegraphics[width=0.2\textwidth]{interp/synth_data/king/king_mvs_08080208.png}}&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/king/king_ps_08080208.png}&
  \fcolorbox{green}{white}{\includegraphics[width=0.2\textwidth]{interp/synth_data/king/king_sl_08080208.png}}\\
  & \multicolumn{4}{c}{(c). tex(0.8), alb(0.8), spec(0.2), rough(0.8)}\\
  PMVS&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/king/king_08080502}&
  \fcolorbox{green}{white}{\includegraphics[width=0.2\textwidth]{interp/synth_data/king/king_mvs_08080502.png}}&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/king/king_ps_08080502.png}&
  \includegraphics[width=0.2\textwidth]{interp/synth_data/king/king_sl_08080502.png}\\
  & \multicolumn{4}{c}{(d). tex(0.8), alb(0.8), spec(0.5), rough(0.2)}\\
  \hline
  ~ & ~ & MVS & PS & SL\\
\end{tabular}
\caption{The first column shows the best algorithm chosen by the mapping. The quantitative and qualitative performance of each technique on the synthetic dataset. The green dots are from the ground truth while the black ones the reconstruction.}
\label{fig:synth_data_results_king}
\end{sidewaysfigure}

\subsubsection{Summary}
We can conclude that the mapping of PMVS and GSL are robust to concavity whereas EPS is relatively more sensitive to concavity due to cast shadows. Therefore, we should put more effort on developing Photometric Stereo algorithms that can reliably deal with cast shadow so that they can be reliably applied to shape with more complex shapes.
% \textbf{(a), (b)} In Figure~\ref{fig:synth_data_results} (a), the mapping predicts that EPS and GSL can give satisfactory results, which is consistent to the quantitative result shown in column 2 and the qualitative resulted labeled in green rectangle. The completeness of the PMVS is low due to the lack of texture.

% \textbf{(c), (d)} In Figure~\ref{fig:synth_data_results} (a), the mapping predicts that all three methods can give satisfactory results, which is consistent to the quantitative result shown in column 2 and the qualitative resulted labeled in green rectangle.

\section{Interpreter}
The framework consists of three separate layers: The first layer is the actual implementation of the algorithms. The second layer is the description of the problem domain. The third layer is the interpretor which receives the description from the user and return an acceptable result. It is responsible for choosing an appropriate 3D reconstruction algorithm based on the description of the problem domain and additional requirements. There are many ways to use the mapping to interprete the problem description. As a proof of concept, we proposed a simple interpreter that consists of two components: mapping and constraints.
\begin{figure}[!htbp]
\centering
\begin{tikzpicture}[node distance=1.2cm, auto]

\node (mapping) [data_nonfixed] {Mapping};
\node (constraint) [data_nonfixed, right of=mapping, xshift=1cm] {Constraints};
\draw[red,thick,solid] ($(mapping.north west)+(-0.3,0.3)$)  rectangle ($(constraint.south east)+(0.3,-0.3)$);

\end{tikzpicture}
\caption{Two components of the Interpreter layer.}
\label{fig:interpreter_layer}
\end{figure}

So far, we have discuss the process of deriving the mapping using synthetic datasets. Now we turn our sights to define the constraints of the framework. Constraints are provided to allow the user to describe the expected result so that a model that most resembles the user's request can be returned by the framework when multiple algorithms can achieve satisfactory results. The following constraints are provided: 
\begin{itemize}
\item depth/shape first: methods that reconstructs surface orientations from a single viewpoint can't retrieve the depth information, thus is refered to as 2.5D reconstruction, such as Shape from Shading, Photometric Stereo, and Shape from (de)focus, \etc. However, these methods generally can reconstruct small scale details, thus achieve much higher detailed results. Intuitively, depth-first would return model with true depth information whereas shape-first would prioritize details and depth information.
\item accuracy/completeness first: methods that achieve high accuracy don't necessary achieve high completeness. This allows the user to choose the algorithm based on the priority level of accuracy and completeness.
\end{itemize}

% We use a very simple ranking system based on accuracy and efficiency: if one algorithm has the same efficiency but is more accurate, or more efficient and equally accurate, it is chosen over the others. (This ranking also allows us to define an efficiency versus accuracy tradeoff for the developer to use.) We could also choose to execute more than one algorithm and accept the results of the one which performed best - however measuring this may be challenging.

\section{Validation of Interpreter}
\label{sec:interp_useful}
Aside from testing whether the description would be correctly mapped to a satisfactory result, we should also verity if a less successful reconstruction would be return given an incorrect description.

\subsection{Real-world Datasets}
We use a similar setup to the synthetic settings and captured a real world dataset for nine objects. The property of these objects are listed in Table~\ref{tab:prop_list_real_data}. Since we don't have the ground truth, we resort to visual analysis to see if the algorithm gives the best reconstruction is consistent to the algorithm suggested by the mapping. We choose four representative objects as representatives of the six classes of objects, they are
\begin{figure}[!htbp]
\centering
\begin{tabular}{c|cccc}
\hline
class \# & 1 & 2 & 3\&4 & 5\&6\\
\hline
  & textureless & textureless & textured & textured\\
description & diffuse & mixed d/s & diffuse & mixed d/s\\
  & bright & bright & dark/bright & dark/bright\\
\hline
object & 
\raisebox{-.5\height}{\includegraphics[width=0.22\textwidth]{interp/real_world_obj/statue/statue}} &
\raisebox{-.5\height}{\includegraphics[width=0.22\textwidth]{interp/real_world_obj/cup/cup}} &
\raisebox{-.5\height}{\includegraphics[width=0.22\textwidth]{interp/real_world_obj/pot/pot}} &
\raisebox{-.5\height}{\includegraphics[width=0.22\textwidth]{interp/real_world_obj/vase/vase}}\\
\end{tabular}
\caption{The rerepsentatives of the six classes of objects used for evaluation.}
\label{fig:test_real_world_6class}
\end{figure}

We use the aforementioned methods to retrieve the parameters of each property, the decomposition of material for each object is presented in Figure~\ref{fig:real_data_material}.
% \begin{table}[!hbtp]
%   \centering
%   \begin{tabular}{*{12}{c}}
%   \multicolumn{3}{l}{\includegraphics[width=0.25\textwidth]{interp/real_world_obj/statue/statue}} &
%   \multicolumn{3}{l}{\includegraphics[width=0.25\textwidth]{interp/real_world_obj/cup/cup}} &
%   \multicolumn{3}{l}{\includegraphics[width=0.25\textwidth]{interp/real_world_obj/pot/pot}} &
%   \multicolumn{3}{l}{\includegraphics[width=0.25\textwidth]{interp/real_world_obj/vase/vase}}\\
%   \includegraphics[width=0.1\textwidth]{interp/real_world_obj/statue/base_00} & & &
%   \includegraphics[width=0.1\textwidth]{interp/real_world_obj/cup/base_00} & &
%   \includegraphics[width=0.1\textwidth]{interp/real_world_obj/pot/base_00} &
%   \includegraphics[width=0.1\textwidth]{interp/real_world_obj/pot/base_01} & &
%   \includegraphics[width=0.1\textwidth]{interp/real_world_obj/vase/base_00} &
%   \includegraphics[width=0.1\textwidth]{interp/real_world_obj/vase/base_01}\\
%   \multicolumn{3}{c}{(d). statue} & \multicolumn{3}{c}{(e). cup} & 
%   \multicolumn{3}{c}{(g). pot} & \multicolumn{3}{c}{(i). vase} \\
%   \end{tabular}
%   \caption{Material of Real-world objects.}
%   \label{fig:real_data_material}
% \end{table}

The property settings of each object is listed in Table~\ref{tab:real_data_prop_list}.
\begin{table}[!htbp]
  \centering
  \begin{tabular}{l*{5}{c}}
  \hline
  \textbf{Property} & Texture & Albedo & Specular & Roughness & Best-suited Algo.\\
  \hline
  status & 0.2 & 0.8 & 0.2 & 0.5 & EPS, GSL\\
  cup & 0.2 & 0.8 & 0.2 & 0.2 & EPS, GSL\\
  pot & 0.8 & 0.2, 0.5 & 0.2 & 0.2 & PMVS\\
  vase & 0.8 & 0.8, 0.2 & 0.5 & 0.2 & PMVS\\
  \hline
  \end{tabular}
  \caption{Property list for the real-world objects}
  \label{tab:real_data_prop_list}
\end{table}

\subsubsection{Data 1: statue}
The first object 

\subsubsection{Data 2: cup}
The second object

\subsubsection{Data 3: pot}
The third object

\subsubsection{Data 4: vase}
The fourth object

\begin{figure}[!htbp]
\centering
\begin{tabular}{c|ccc|c}
& \multicolumn{3}{c}{Qualitative results} & Baseline\\
Mapping & PMVS & EPS & GSL & VH\\
\hline
EPS, GSL & 
\raisebox{-.5\height}{\includegraphics[width=0.2\textwidth]{interp/real_data/statue/statue_mvs}}&
\fcolorbox{green}{white}{\raisebox{-.5\height}{\includegraphics[width=0.2\textwidth]{interp/real_data/statue/statue_ps}}}&
\fcolorbox{green}{white}{\raisebox{-.5\height}{\includegraphics[width=0.2\textwidth]{interp/real_data/statue/statue_sl}}}&
\raisebox{-.5\height}{\includegraphics[width=0.2\textwidth]{interp/real_data/statue/statue_sc}}\\
EPS, GSL &
\raisebox{-.5\height}{\includegraphics[width=0.2\textwidth]{interp/real_data/cup/cup_mvs}}&
\fcolorbox{green}{white}{\raisebox{-.5\height}{\includegraphics[width=0.2\textwidth]{interp/real_data/cup/cup_ps}}}&
\fcolorbox{green}{white}{\raisebox{-.5\height}{\includegraphics[width=0.2\textwidth]{interp/real_data/cup/cup_sl}}}&
\raisebox{-.5\height}{\includegraphics[width=0.2\textwidth]{interp/real_data/cup/cup_sc}}\\
PMVS &
\fcolorbox{green}{white}{\raisebox{-.5\height}{\includegraphics[width=0.2\textwidth]{interp/real_data/pot/pot_mvs}}}&
\raisebox{-.5\height}{\includegraphics[width=0.2\textwidth]{interp/real_data/pot/pot_ps}}&
\raisebox{-.5\height}{\includegraphics[width=0.2\textwidth]{interp/real_data/pot/pot_sl}}&
\raisebox{-.5\height}{\includegraphics[width=0.2\textwidth]{interp/real_data/pot/pot_sc}}\\
PMVS &
\fcolorbox{green}{white}{\raisebox{-.5\height}{\includegraphics[width=0.2\textwidth]{interp/real_data/vase/vase_mvs}}}&
\raisebox{-.5\height}{\includegraphics[width=0.2\textwidth]{interp/real_data/vase/vase_ps}}&
\raisebox{-.5\height}{\includegraphics[width=0.2\textwidth]{interp/real_data/vase/vase_sl}}&
\raisebox{-.5\height}{\includegraphics[width=0.2\textwidth]{interp/real_data/vase/vase_sc}}\\
\hline
\end{tabular}
\caption{The evaluation of the effectiveness of the mapping using real-world object. The well reconstructed object is label by green rectangle.}
\end{figure}

\section{Summary}
Building upon our description and mapping, we are able to develop a proof of concept interpreter which interpretes the model of the problem, selects the most appropriate algorithm base on the mapping and return a reliable reconstruction result.

The development of more complex desription of object geometry and material, incorporation of new algorithms and the improvement of the mapping is an ongoing process to improve the framework.
