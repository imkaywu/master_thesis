%% The following is a directive for TeXShop to indicate the main file
%%!TEX root = diss.tex

\chapter{Introduction}
\label{ch:Introduction}
% [introduction to 3D reconstruction]\\
Modeling of the 3D world has been an active research topic in computer vision for decades and has a wide range of applications including 3D mapping and navigation, online shopping, 3D printing, computational photography, video games, visual effects, and cultural heritage archival. The goal of 3D modeling is to reconstruct a 3D geometric model represented by point cloud, voxel grid, depth maps, or surface mesh, from RGB or range sensors, optionally incorporating the material of the surface.

% [current situation and context]\\
Achieving this goal is an extremely challenging task, as it involves the reverse process of image formation, which is highly likely to result in a variety of possible results and solutions. To overcome this challenge, some assumptions must be made in terms of materials, viewpoints, and lighting conditions. In turn, a solid understanding of the interaction of light with surface geometry and material is a prerequisite to fully take advantage of the existing techniques. In past decades, we have witnessed a variety of tools and approaches to 3D modeling applied successfully to an assortment of sub-domains, such as Computer Aided Design (CAD) tools~\cite{CAD}, arm-mounted probes, active methods~\cite{bernardini2002building,levoy2000digital,Lidar,kinect} and passive image-based methods~\cite{kutulakos2000theory,furukawa2010accurate,faugeras2002variational,goesele2006multi}. Among the existing approaches, active techniques such as laser scanners~\cite{levoy2000digital}, Structured Light (SL) systems~\cite{bernardini2002building}, and Photometric Stereo (PS)~\cite{woodham1980photometric}, as well as passive methods such as Multi-View Stereo (MVS)~\cite{seitz2006comparison}, have been the most successful. Laser scanners and structured light techniques are seen to generate the most accurate results, but are generally complicated to set up and calibrate, time consuming to scan, and demanding to store and process in terms of memory. Photometric Stereo is able to achieve highly detailed reconstruction comparable to that of laser scanners, but the true depth information is lost due to the use of a single viewpoint. Further, MVS requires minimal setup and can work in both controlled, small scale lab settings as well as outdoor, medium to large scale environments. However, the quality of reconstruction is generally noisier, and is susceptible to the texture and material property of the surface. All of the aforementioned techniques requires an understanding of calibration, stereo correspondence, physics-based vision, and so on, which are not easy tasks to master.

% [motivation]\\
Regardless of past successes and strong demands across various areas, we have not yet witnessed any substantial progress in terms of making the mentioned techniques accessible to application developers or system designers (termed \textit{users} for the rest of the thesis), who generally have little or no computer vision expertise. We've made two key observations about computer vision algorithms: 1) few of these methods works well under all circumstances, nor do they share the same setup or inputs/outputs, making it difficult for developers to choose an optimal method for their particular application; 2) expertise knowledge is a prerequisite to fully exploit the potentials of existing vision techniques. These observations lead us to the following question which we address in this thesis: is it achievable to create an interface that can return a reliable reconstruction by one of the best possible algorithms based on the descriptions of the object or scene to be reconstructed?

The interface consists of the following three layers, see Figure~\ref{fig:interface_overview}: the \textit{description layer} sits on top and acts as the medium between the user and the lower layers. It is through this that the user provides a description of the 3D reconstruction problem. The description is passed to the \textit{interpreter} layer, which chooses appropriate algorithms given the description, and then configures each algorithm's parameters. The interpreter can also define any necessary pre or post-processing operations (such as noise removal or image scaling). The lowest layer of the three is where the \textit{algorithms} sit.
\begin{figure}[!htbp]
\centering
\begin{tikzpicture}[node distance=1cm, auto]

\node (desc) [data] {L3: Description};
\node (interp) [data, below of=desc] {L2: Interpreter};
\node (algo) [data, below of=interp] {L1: Algorithm};
% \draw[red,thick,solid] ($(desc.north west)+(-0.3,0.3)$)  rectangle ($(algo.south east)+(0.3,-0.3)$);

\end{tikzpicture}
\caption{The three layers of the 3D reconstruction interface.}
\label{fig:interface_overview}
\end{figure}

% The mental model to our approach is similar to that of the game `name that object': one participant makes guesses of what the object is based solely on the descriptions of the appearance provided by the other participant. In our case, the key idea is to construct an algorithm-free interface above the algorithms themselves, so that one or multiple appropriate algorithms can be selected based on the `appearance' of the object described by the developers.

% \section{Problem definition}
% The problem we address in this thesis can be described as: construct a mapping with the description of the object as input, returning the best possible reconstruction result by one algorithm from a suite of algorithms.

\section{Outline}
The problem addressed in this thesis can be described as follows: construct an interface for 3D reconstruction that can return a reliable reconstruction result by one of the best-suited algorithms, which is determined by the description of the problem condition. More specifically, a taxonomy is proposed that transforms the 3D reconstruction problem from one requiring knowledge of algorithmic details to one that is based on the correlation between the problem space and algorithms. Next, a well defined model and representations are developed to describe the problem space definitively. Lastly, mapping between the problem space and the algorithms is discovered, from which a proof-of-concept interpreter is proposed. A rigorous evaluation is then carried out to verify the robustness of the interpreter. 

\subsection{Related Work}
We discuss the existing software and toolboxes for 3D reconstruction, and present the required vision background needed to fully take advantage of these toolboxes. A review of the 3D acquisition techniques is provided, organized by the visual and geometric cues used for reconstruction.

\subsection{A Problem space of 3D Reconstruction}
Existing softwares and algorithms focus on providing algorithmic solutions to problems, which we call a \textit{algorithm-center approach}. This approach provides little insight to the problem conditions that a specific algorithm is applicable to. We proposed a \textit{problem-centered approach} that gives a well-defined problem space, which allows further investigation of the relation between problem conditions and algorithms. This relation can be used to choose a best possible algorithm based on described problem condition. The problem condition consists of a variety of visual and geometric properties of objects. The collective problem conditions is called \textit{problem condition space}, or in short \textit{problem space}.

\subsection{A Description of 3D Reconstruction}
In previous cases, the mapping from a problem space to an algorithm has been ambigueous due to the problem space that is poorly defined. Here, we set out to provide a rigorous definition of the problem space itself. First, a formal and practical definition of the 3D reconstruction problem based on set theory is proposed. Second, a model consisting of key object properties is developed. Third, the representations of the problem are proposed. Lastly, common 3D reconstruction tasks are expressed using the proposed model and representations.
% \begin{figure}[!htbp]
% \centering
% \begin{tikzpicture}[node distance=1.2cm, auto]

% \node (exp) [data] {Expressions};
% \node (rep) [data, below of=exp] {Representation};
% \node (model) [data, below of=rep] {Model};
% \node (def) [data, below of=model] {Definition};
% \draw[red,thick,solid] ($(exp.north west)+(-0.3,0.3)$)  rectangle ($(def.south east)+(0.3,-0.3)$);

% \end{tikzpicture}
% \caption{The three layer of the 3D reconstruction interface.}
% \label{fig:interface_overview}
% \end{figure}

\subsection{A Mapping of 3D Reconstruction}
To derive a more precise mapping from problem space to algorithm space, we need to evaluate the performance of the selected algorithms under varied properties and their combinations. We use synthetic datasets to achieve this goal. Part of the challenge in establishing a comprehensive set of experiments for such an evaluation is the large variations of shapes and material properties. To overcome this issue, we first establish the \textit{effective problem domain} (EPS) by finding the effective properties. Then we evaluate the performance of each algorithm within the EPD, which serves as the basis of the mapping.
% \begin{figure}[!htbp]
% \centering
% \begin{tikzpicture}[node distance=1.5cm, auto]

% \node (depend_check) [process] {Denpendency Check};
% \node (prop_set) [data, above of=depend_check, xshift=-2cm, yshift=0.25cm] {Property Set};
% \node (algo) [data, above of=depend_check, xshift=2cm, yshift=0.25cm]{Algo. i};
% \node (depend_prop) [data, below of=depend_check] {Dependent Property Set};
% \node (train) [process, below of=depend_prop] {Training};
% \node (cond_mat) [data, below of=train] {Condition matrix};

% \draw (prop_set.south) -- ++(0.0, -0.25) coordinate (inter0);
% \draw (inter0) -- ++(2.0, 0.0) coordinate (inter1);
% \draw (algo.south) -- ++(0.0, -0.25) coordinate (inter2);
% \draw (inter2) -- ++(-2.0, 0.0) coordinate ();
% \draw [arrow] (inter1) -- (depend_check);
% \draw [arrow] (depend_check) -- (depend_prop);
% \draw [arrow] (depend_prop) -- (train);
% \draw [arrow] (train) -- (cond_mat);
% \draw[red,thick,dotted] ($(prop_set.north west)+(-0.3,0.3)$)  rectangle ($(cond_mat.south east)+(2.3,-0.3)$);

% \end{tikzpicture}
% \caption{The process of obtaining the condition matrix for an algorithm.}
% \label{fig:mapping_overview}
% \end{figure}

\subsection{An Interpretation of 3D Reconstruction}
We conduct the evaluation of the interface around two key evaluation questions: 1) can the derived mapping be extended to an object with a different shape; 2) can the proof-of-concept interpreter return a reliable result given the correct description to the problem condition. To answer these questions, we carry out two separate experiments: In Section~\ref{sec:eval_mapping}, we use synthetic objects with the same configurations as the ones used to derive the mapping, and check if the mapping is consistent for different objects across varied problem conditions; in Section~\ref{sec:eval_interp}, we use synthetic and real-world datasets to evaluate the interpreter.
% \begin{figure}[ht]
% \centering
% \begin{tikzpicture}[node distance=2cm, auto]
% % depend_check, and training
% \node (depend_check) [process] {Denpendency Check};
% \node (prop_set) [data, above of=depend_check, xshift=-2cm, yshift=0.5cm] {Property Set};
% \node (algo) [data, above of=depend_check, xshift=2cm, yshift=0.5cm]{Algo. i};
% \node (depend_prop) [data, below of=depend_check] {Dependent Property Set};
% \node (train) [process, below of=depend_prop] {Training};
% \node (prfm_algo) [data, below of=train] {Performance of Algo. i};
% \node [data, draw=none, fill=none, left of=prop_set, xshift=-1.2cm] {Chapter~\ref{ch:3DRecon_Mapping}: 3D Benchmark};

% % 3D taxonomy
% \node (algorithm) [model, above of=algo, yshift=1.8cm] {Algorithms};
% \node (translucency) [data_nonfixed, below of=algorithm, xshift=-3.9cm] {Translucency};
% \node (texture) [data_nonfixed, right of=translucency, xshift=0.1cm]{Texture};
% \node (lightness)[data_nonfixed, right of=texture, xshift=-0.2cm]{Lightness};
% \node (reflection)[data_nonfixed, right of=lightness, xshift=0.0cm]{Reflection};
% \node (rough)[data_nonfixed, right of=reflection, xshift=0.1cm]{Roughness};
% \node (3d_taxo) [dotted, draw=red, fill=none, thick, fit=(algorithm) (translucency) (texture) (lightness) (reflection) (rough), inner sep=0.3cm] {};
% \node [data, draw=none, fill=none, above of=3d_taxo, yshift=0.4cm] {Chapter~\ref{ch:3DRecon_Taxo}: 3D Taxonomy};

% % 3D interpretation
% \node (abstract) [process, below of=prfm_algo]{Mapping};
% \node (best_algo) [data, right of=abstract, xshift=2cm] {Best-suited algorithm(s)};
% \node [data, draw=none, fill=none, below of=abstract, yshift=0.4cm] {Chapter~\ref{ch:3DRecon_Interp}: 3D Interpretation};

% % 3D model
% \node (def) [data, left of=abstract, xshift=-3cm, yshift=6cm)] {Definition};
% \node (model) [data, below of=def] {Model};
% \node (rep) [data, below of=model] {Representation};
% \node (exp) [data, below of=rep] {Expressions};
% \node [data, draw=none, fill=none, above of=def, yshift=-0.5cm] {Chapter~\ref{ch:3DRecon_Desc}: 3D Model};

% % depend_check, and training
% \draw (prop_set.south) -- ++(0.0, -0.5) coordinate (inter0);
% \draw (inter0) -- ++(2.0, 0.0) coordinate (inter1);
% \draw (algo.south) -- ++(0.0, -0.5) coordinate (inter2);
% \draw (inter2) -- ++(-2.0, 0.0) coordinate ();
% \draw [arrow] (inter1) -- (depend_check);
% \draw [arrow] (depend_check) -- (depend_prop);
% \draw [arrow] (depend_prop) -- (train);
% \draw [arrow] (train) -- (prfm_algo);
% \draw [arrow] (prfm_algo) -- (abstract);
% \draw[red,thick,dotted] ($(prop_set.north west)+(-0.3,0.3)$)  rectangle ($(prfm_algo.south east)+(2.3,-0.3)$);

% \draw (algorithm.south) -- ++(0.0, -0.5) coordinate (c);
% \draw (c) -- ++(-1.8, 0.0) coordinate (n1);
% \draw [arrow](n1) -- (texture.north);
% \draw (n1) -- ++(-2.1, 0.0) coordinate (n2);
% \draw [arrow](n2) -- (translucency.north);
% \draw [arrow](c) -- (lightness.north);
% \draw (c) -- ++(2.0, 0.0) coordinate (p1);
% \draw [arrow](p1) -- (reflection.north);
% \draw (p1) -- ++(2.1, 0.0) coordinate (p2);
% \draw [arrow](p2) -- (rough.north);
% \draw [arrow] (3d_taxo) -- (algo);

% % 3D model
% \draw (def) -- (model);
% \draw (model) -- (rep);
% \draw (rep) -- (exp);
% \draw [arrow] (exp) -- (abstract);
% \draw[red,thick,dotted] ($(def.north west)+(-0.3,0.3)$)  rectangle ($(exp.south east)+(0.3,-0.3)$);

% % 3D interpretation
% \draw [arrow] (abstract) -- (best_algo);
% \draw[red,thick,dotted] ($(exp.north west)+(-0.3,0.3)$)  rectangle ($(best_algo.south east)+(0.3,-0.3)$);
% \end{tikzpicture}
% \caption{Thesis overview. Rectangles denote process. Rounded rectangles represents data or component.}
% \label{fig:system_overview}
% \end{figure}

\section{Contributions}
% The main contribution of this thesis is the development and evaluation of a interface for the 3D reconstruction problem in computer vision, to hide the details of specific methods. An abstraction may be employed by users to describe the conditions of the vision problems they are trying to solve, and our novel interpreter uses such descriptions to select an appropriate algorithm and return a reliable result.
The main contribution of this thesis is the development and application of an interface for a subset of 3D reconstruction problem, which hides algorithmic details and allows users to describe conditions surrounding the problem. We focus on a subset of problem, which is defined in Chapter~\ref{ch:3DRecon_ProbSpace}, to approach this problem in a tractable manner. This described conditions, which consists of varied visual and geometric properties, can be interpreted so that an appropriate algorithm is chosen to reconstruct a successful result. This endeavor is non-trivial for two reasons: 1) currently, most approaches can only achieve satisfactory results on a limited set of categories of objects; 2) a solid understanding of reconstruction algorithm details is a prerequisite to fully take advantage of the existing techniques, which is difficult for application developers to obtain. To some extent, our interface attempts to expand the problem space by incorporating multiple algorithms. Though it can cover a wider range of problem space than a single algorithm, it is still confined within the space covered by currently existing techniques. Thus, our evaluation is carried out within the problem space covered by the selected algorithms.
% The significant aspects of our approach are presented in further detail below:

% \noindent\textbf{1. A taxonomy of the 3D reconstruction problem that focuses on problem conditions instead of algorithmic details.}

% Typical taxonomies generally focus on one class of algorithms and are algorithm centric. Normally they describe and classify intra-class algorithms based on \textit{how} an algorithm solves a problem. For instance, MVS algorithms can be categorized based on visibility models or scene representations, and PS methods can be classified by reflectance models. While this type of taxonomy provides a decent basis for comparison of intra-class algorithms, it provides little insight into the conditions where techniques can perform well, which is crucial when it comes to designing an application that requires reliable reconstruction techniques. Thus this thesis introduces a new perspective of taxonomy for 3D reconstruction that is based on the conditions surrounding the problem. Further, we address the lack of progress in certain areas of this research field, which will be helpful for redirecting research efforts to less explored territories.

% \noindent\textbf{2. A description of the 3D reconstruction problem that allows increased precision in mapping from a well-defined problem space to algorithms.}

% Much of the recent research in this area has been focused on technical novelties. However, we need to pay equal attention to the conditions under which algorithms are designed, in order to return reliable results. One of the reasons for this oversight is the ambiguity of the problem domain. Information regarding the set of conditions under which a given algorithm performs well is difficult to convey without an agreed upon model representing the problem space itself. Conversely, knowledge of which algorithm best suits a particular set of conditions in the problem space is also difficult to determine without a model to represent such conditions. Therefore, it's crucial to have a better understanding of the problem space so that we can exploit the working space of algorithms.

% \noindent\textbf{3. A mapping from the description of the object to appropriate algorithms.}

% Given an algorithm, the conditions under which this specific algorithm works well is largely unclear. Additionally, given a specific problem conition, the knowledge of which algorithm performs well under this problem condition is empirical. Therefore, we need to find a precise mapping from the well defined problem space to determine a reliable solution. Here the effective conditions of a specific algorithm is discovered by evaluating performance under the well defined problem conditions.

\section{Organization}
We organize this thesis as follows. Chapter~\ref{ch:RelatedWork} briefly introduces 3D reconstruction toolboxes and gives an overview of current landscape of 3D reconstruction field. In Chapter~\ref{ch:3DRecon_ProbSpace}, we propose a simplified problem space of 3D reconstruction problems and propose four problem conditions that will be investigated in depth. In Chapter~\ref{ch:3DRecon_Desc}, we provide a formal description of problem condition of a 3D reconstruction problem. In Chapter~\ref{ch:3DRecon_Mapping}, we develop the relation from problem condition to algorithms by evaluating the performance of a selection of algorithms under varied problem conditions. In Chapter~\ref{ch:3DRecon_Interp}, we use both synthetic and real-world datasets to demonstrate the interpretation of the 3D reconstruction description and the robustness of the proof-of-concept interpreter.