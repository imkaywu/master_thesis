%% The following is a directive for TeXShop to indicate the main file
%%!TEX root = diss.tex

\chapter{Introduction}
\label{ch:Introduction}
% [introduction to 3D reconstruction]\\
Modelling of the 3D world has been an active research topic in computer vision for decades. The goal is to reconstruct a 3D geometric model, represented by point cloud, voxel grid, depth maps, or surface mesh, from RGB or range sensors, optionally with the material of the surface. It has a wide range of applications including 3D mapping and navigation, online shopping, 3D printing, computational photography, video games, visual effects, and cultural heritage archival.

% [current situation and context]\\
We've witness a variety of tools and approaches such as Computer Aided Design (CAD) tools~\cite{CAD}, arm-mounted probes, active methods~\cite{bernardini2002building,levoy2000digital,Lidar,kinect} and passive image-based methods~\cite{kutulakos2000theory,furukawa2010accurate,faugeras2002variational,goesele2006multi} applied successfully to some sub-domains of the problem. Among the existing techniques, active techniques such as laser scanner~\cite{levoy2000digital}, structured light system (SL)~\cite{bernardini2002building}, and Photometric Stereo (PS)~\cite{woodham1980photometric}, and passive method such as Multi-view Stereo (MVS)~\cite{seitz2006comparison} have been the most successful ones. Laser scanners and structured light techniques can generate the most accurate results, but is generally complicated to set up and calibrate, time consuming to scan, and memory demanding to store and process. Photometric Stereo is able to achieve highly detailed reconstruction comparable to that of laser scanner, but the true depth information is lost due to the use of a single viewpoint. MVS requires minimal setup and works in both controlled, small scale lab setting or a outdoor, medium to large scale environments. However, the quality of the reconstruction is generally noisier, and is susceptible to the texture and material property of the surface. All these techniques requires an understanding of calibration, stereo correspondence, physics-based vision, and etc, which is no easy task to master. Furthermore, this is an extremely challenging task since it's the reverse process of image formation, which is highly likely to have more than one plausible results. To overcome this challenge, some assumptions have to be made in terms of the materials, viewpoints, and lighting, which adds additional layer of complexity to the inherit complexity of the specific reconstruction technique. A solid understanding of the interaction of lighting with surface geometry and material is a prerequisite to fully take advantage of these existing techniques.

% [motivation]\\
Regardless of the success in the past and the substantial need for this technology, we have not yet witnessed any substantial progress in terms of making those techniques accessible to application developers who generally have little or no computer vision expertise. These developers generally focus more on the development of the application, have a good understanding of the properties of the target objects for their application domain, and are good at learning programming API rather than vision algorithms. We've made two key observations about computer vision algorithms: 1) none of these methods works well under all circumstances, nor do they require the same setup or inputs/outputs, making it difficult for developers to choose the optimal method for their particular application; 2) expertise knowledge is a prerequisite to fully exploit the potentials of existing vision techniques. These observations lead us to the question: is it possible to create a computer vision abstraction that makes the selection of a particular algorithm based on the descriptions of the object or scene to be reconstructed. By doing so, we can encapsulate computer vision experts' knowledge of their algorithms strengths within the abstraction so that a developer need only describe the problem they need solved. The mental model to our approach is similar to that of the game `name that object': one participant takes guesses of what the object is based solely on the descriptions of the appearance provided by the other participant. In our case, the key idea is to construct an algorithm-free abstraction around the detailed algorithms and implementations so that one or multiple best suited ones can be selected based on the `appearance' of the object described by the developers. The developers use the abstraction's description interface that is structured to match how vision problems can be described based on a model of a 3D scene and translated to parameters useful for determining which algorithms would work best.

\section{Problem definition}
The problem we address in this thesis can be described as: find a small set of visual and geometric properties, from which an descriptive abstraction is formed to find the best-suited algorithm(s) to reconstruct the target object. The 

\subsection{Scope}
To limit the scope of this work, we make the following assumptions:

\subsubsection{Simplified reflectance model}
Since the majority of reconstruciton techniques rely on observing light reflected off a surface, surfaces exhibit significant effect of global light tranport present a huge challenge to the reconstruction problem. Surface exhibits global light transport, including \textit{specular}, \textit{transmission}, \textit{sub-surface scattering}, \textit{inter-reflection}, \textit{self-shadow}, and etc would break the assumptions made by most generic 3D reconstruction algorithms. Thus the global light transport are ignored, and the reflection properties of consideration are \textit{albedo}, \ie the ratio of reflected light w.r.t the received light, and \textit{specularity}, \ie the amount of specular reflection. A more comprehensive model should be constructed based on our work to incorporate more complex phenomena to be more comprehensive.

\subsubsection{Simplified geometric model}
It's a challenging task to model geometry using mathematical descriptions. For geometric primitives such as cube, sphere, or cone, etc, it's possible to describe the shape using concise descriptions. However, the task becomes prohibitive when it comes to shapes with varied characteristics. Furthermore it becomes more ambiguous when natural language is employed. Thus we only consider the microscopic roughness of the surface, which has a direct relation with the reflection. Other prominent geometric properties such as \textit{concavity}, which affects self-shadow, inter-reflection, \textit{depth-discontinuity}, which affects the depth estimation, are ignored.

\subsubsection{Simplified object class}
Only a subset of visual/geometric properties are considered, which include texture, lightness, specular, and roughness. Since we use a simplified reflectance and geometric model, phenomena such as translucency, subsurface scattering, refraction, occlusion, concavity can not be described properly. Thus object exhibiting those properties are not considered in the evaluation.

\subsection{Data}
We use both a synthetic and a real-world dataset. The synthetic dataset is generated by a physically-based renderer Cycles with varied reflectant and geometric properties, including texture, albedo, specular,and roughness. We used the similar setup to capture real-world images of 11 objects to further test the validity of our proposed abstraction.

\section{Thesis outline}
We present a flow chart to summarize the complete working of the system, as shown in Figure~\ref{fig:system_overview}.

\subsubsection{Related Work}
We discuss the existing softwares and toolboxes for 3D reconstruction, and present the minimum vision background needed to fully take advantage of those toolboxes. Then a review of 3D acquisition techniques is provided, organized by the visual and geometric cues used for reconstruction.

\subsubsection{Taxonomy of Algorithms}
The majority of taxonomy of 3D reconstruction utilizes the differences of the algorithmic details as taxonomy axes. For instance, MVS algorithms can be categorized based on various visibility models or scene representations, and PS methods can be classified by the reflectance models. However, it doesn't provide the context or the applicability of these techniques. Thus the proposed taxonomy categorize algorithms from an object-centered perspective, \ie algorithms are classified based on the class that the object belongs to.

\subsubsection{Description of 3D Reconstruction}
Once we have a taxonomy of algorithm based on object class, a model of the 3D reconstruction problem needs to be developed. This model should give a clear and distinct description of the task that doesn't require much vision knowledge and general enough that is not object specific. This includes a formal/applied definition of the 3D reconstruction problem, the representation, and lastly, the expression.

\subsubsection{Mapping of 3D Reconstruction}
The abstraction consists of mappings from a property set and all its combination to algorithms that can achieve satisfactory results. To construct such mappings, we need to evaluate the performance of the selected algorithm under varied properties and their combinations.

We use synthetic datasets to achieve this goal. Part of the challenge in establishing a comprehensive set of experiments for such an evaluation is the large variability of shapes and material properties. To overcome this issue, we first investigate the dependent properties, which are properties that have influence on one another, thus must be considered jointly. Then we evaluate the performance the each algorithm under the conditions of dependent properties and all their combinations, which makes up our abstraction.

\subsubsection{Interpretation of 3D Reconstruction}
We use both synthetic and real-world datasets to evaluate the proposed abstraction. We used three synthetic objects: a cup, a pot, and a vase. For the real-world dataset, we use the similar setups and captured the images for 11 objects with various shape and material properties.
\begin{figure}[ht]
\centering
\begin{tikzpicture}[node distance=2cm, auto]
% depend_check, and training
\node (depend_check) [process] {Denpendency Check};
\node (prop_set) [data, above of=depend_check, xshift=-2cm, yshift=0.5cm] {Property Set};
\node (algo) [data, above of=depend_check, xshift=2cm, yshift=0.5cm]{Algo. i};
\node (depend_prop) [data, below of=depend_check] {Dependent Property Set};
\node (train) [process, below of=depend_prop] {Training};
\node (prfm_algo) [data, below of=train] {Performance of Algo. i};
\node [data, draw=none, fill=none, left of=prop_set, xshift=-1.2cm] {Chapter~\ref{ch:3DRecon_Benchmark}: 3D Benchmark};

% 3D taxonomy
\node (cue) [model, above of=algo, yshift=1.8cm] {Visual Cues};
\node (stereo) [data_nonfixed, below of=cue, xshift=-3cm] {Stereo};
\node (shading) [data_nonfixed, below of=cue, xshift=-1cm] {Shading};
\node (silhouette) [data_nonfixed, below of=cue, xshift=1cm] {Silhouette};
\node (more) [data_nonfixed, below of=cue, xshift=3cm] {...};
\node (3d_taxo) [dotted, draw=red, fill=none, thick, fit=(cue) (stereo) (shading) (silhouette) (more), inner sep=0.3cm] {};
\node [data, draw=none, fill=none, above of=3d_taxo, yshift=0.4cm] {Chapter~\ref{ch:3DRecon_Taxo}: 3D Taxonomy};

% 3D interpretation
\node (abstract) [process, below of=prfm_algo]{Abstraction};
\node (best_algo) [data, right of=abstract, xshift=2cm] {Best-suited algorithm};
\node [data, draw=none, fill=none, below of=abstract, yshift=0.4cm] {Chapter~\ref{ch:3DRecon_Interp}: 3D Interpretation};

% 3D model
\node (def) [data, left of=abstract, xshift=-3cm, yshift=6cm)] {Definition};
\node (model) [data, below of=def] {Model};
\node (rep) [data, below of=model] {Representation};
\node (exp) [data, below of=rep] {Expressions};
\node [data, draw=none, fill=none, above of=def, yshift=-0.5cm] {Chapter~\ref{ch:3DRecon_Desc}: 3D Model};

% depend_check, and training
\draw (prop_set.south) -- ++(0.0, -0.5) coordinate (inter0);
\draw (inter0) -- ++(2.0, 0.0) coordinate (inter1);
\draw (algo.south) -- ++(0.0, -0.5) coordinate (inter2);
\draw (inter2) -- ++(-2.0, 0.0) coordinate ();
\draw [arrow] (inter1) -- (depend_check);
\draw [arrow] (depend_check) -- (depend_prop);
\draw [arrow] (depend_prop) -- (train);
\draw [arrow] (train) -- (prfm_algo);
\draw [arrow] (prfm_algo) -- (abstract);
\draw[red,thick,dotted] ($(prop_set.north west)+(-0.3,0.3)$)  rectangle ($(prfm_algo.south east)+(2.3,-0.3)$);

% 3D taxonomy
\draw (cue.south) -- ++(0.0, -0.5) coordinate (n2);
\draw (n2) -- ++(-1.0, 0.0) coordinate (n1);
\draw [arrow] (n1) -- (shading.north);
\draw (n1) -- ++(-2.0, 0.0) coordinate (n0);
\draw [arrow] (n0) -- (stereo.north);
\draw (n2) -- ++(1.0, 0.0) coordinate (n3);
\draw [arrow] (n3) -- (silhouette.north);
\draw (n3) -- ++(2.0, 0.0) coordinate (n4);
\draw [arrow] (n4) -- (more.north);
\draw [arrow] (3d_taxo) -- (algo);

% 3D model
\draw [arrow] (def) -- (model);
\draw [arrow] (model) -- (rep);
\draw [arrow] (rep) -- (exp);
\draw [arrow] (exp) -- (abstract);
\draw[red,thick,dotted] ($(def.north west)+(-0.3,0.3)$)  rectangle ($(exp.south east)+(0.3,-0.3)$);

% 3D interpretation
\draw [arrow] (abstract) -- (best_algo);
\draw[red,thick,dotted] ($(exp.north west)+(-0.3,0.3)$)  rectangle ($(best_algo.south east)+(0.3,-0.3)$);
\end{tikzpicture}
\caption{Thesis overview. Rectangles denote process. Rounded rectangles represents data or component.[To be re-done]}
\label{fig:system_overview}
\end{figure}

\section{Contributions}
The main contributions are:

\noindent\textbf{1. A new taxonomy of 3D reconstruction problem from object-centered perspective.}

The previous taxonomies generally focus on one class of algorithms, and thus can only deal with a specific class of objects. The proposed taxonomy address this issue by considering the criteria from an object-centered perspective, \ie classify the algorithm based on the object classes that can be reliably reconstructed.

\noindent\textbf{2. A description of 3D reconstruction that can describe 3D reconstruction problem using visual/geometric properties.}

A formal and a practical definition of the 3D reconstruction problem is proposed, followed by a model and representation, which can be used to describe a 3D reconstruction problem, NOT from an algorithmic point of view, but in an object-centered manner.

\noindent\textbf{3. A mapping of 3D reconstruction that maps problem description to a suite of algorithms.}

A mapping that maps a description of 3D reconstruction problem into a set of appropriate algorithms are derived from the synthetic dataset. The process of finding the mapping is discussed in depth, which includes a dependency checking step to identify all the dependent properties to reduce the dimensions of the problem domain, and a training step to evaluate the performance under all dependent properties and their combinations. This mapping builds upon the results from the training step.

\section{Organization}
We organize this thesis as follows: we discuss the related work in Chapter~\ref{ch:RelatedWork}. In Chapter~\ref{ch:3DRecon_Taxo} we provide a new taxonomy of 3D reconstruction based on object class. In Chapter~\ref{ch:3DRecon_Desc}, we provide a formal description of the 3D reconstruction problem, which can be applied to the currently existing techniques, and extended to future algorithms. In Chapter~\ref{ch:3DRecon_Mapping}, we discuss the process of generating a synthetic dataset to evaluate the performance of a selected set of techniques under the condition of different properties, which serves as the basis for the mapping of 3D reconstruction. In Chapter~\ref{ch:3DRecon_Interp}, we use both synthetic and real-world datasets to demonstrate the interpretation of the 3D reconstruction description and the validity of the proposed mapping.