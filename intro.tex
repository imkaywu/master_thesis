%% The following is a directive for TeXShop to indicate the main file
%%!TEX root = diss.tex

\chapter{Introduction}
\label{ch:Introduction}
% [introduction to 3D reconstruction]\\
Modeling of the 3D world has been an active research topic in computer vision for decades and has a wide range of applications including 3D mapping and navigation, online shopping, 3D printing, computational photography, video games, visual effects, and cultural heritage archival. The goal in 3D modeling is to reconstruct a 3D geometric model represented by point cloud, voxel grid, depth maps, or surface mesh, from RGB or range sensors, optionally incorporating the material of the surface.

% [current situation and context]\\
Achieving this goal is an extremely challenging task, as it involves the reverse process of image formation, which is highly likely to result in a variety of possible results and solutions. To overcome this challenge, some assumptions must be made in terms of materials, viewpoints, and lighting involved. In turn, a solid understanding of the interaction of lighting with surface geometry and material is a prerequisite to fully take advantage of the existing techniques. In past decades, we have witnessed a variety of tools and approaches to 3D modeling applied successfully to an assortment of sub-domains, such as Computer Aided Design (CAD) tools~\cite{CAD}, arm-mounted probes, active methods~\cite{bernardini2002building,levoy2000digital,Lidar,kinect} and passive image-based methods~\cite{kutulakos2000theory,furukawa2010accurate,faugeras2002variational,goesele2006multi}. Among the existing approaches, active techniques such as laser scanners~\cite{levoy2000digital}, Structured Light (SL) systems~\cite{bernardini2002building}, and Photometric Stereo (PS)~\cite{woodham1980photometric}, as well as passive methods such as Multi-View Stereo (MVS)~\cite{seitz2006comparison}, have been the most successful. Laser scanners and structured light techniques are seen to generate the most accurate results, but are generally complicated to set up and calibrate, time consuming to scan, and demanding to store and process in terms of memory. Photometric Stereo is able to achieve highly detailed reconstruction comparable to that of laser scanners, but the true depth information is lost due to the use of a single viewpoint. Further, MVS requires minimal setup and can work in both controlled, small scale lab settings as well as outdoor, medium to large scale environments. However, the quality of reconstruction is generally noisier, and is susceptible to the texture and material property of the surface. All of the aforementioned techniques requires an understanding of calibration, stereo correspondence, physics-based vision, and so on, which are not easy tasks to master.

% [motivation]\\
Regardless of past successes and strong demands across various areas, we have not yet witnessed any substantial progress in terms of making the mentioned techniques accessible to application developers who generally have little or no computer vision expertise. We've made two key observations about computer vision algorithms: 1) none of these methods works well under all circumstances, nor do they share the same setup or inputs/outputs, making it difficult for developers to choose an optimal method for their particular application; 2) expertise knowledge is a prerequisite to fully exploit the potentials of existing vision techniques. These observations lead us to the following question which we address in this thesis: is it achievable to create a framework that can return a reliable reconstruction by one of the best possible algorithms based on the descriptions of the object or scene to be reconstructed? 

The mental model to our approach is similar to that of the game `name that object': one participant makes guesses of what the object is based solely on the descriptions of the appearance provided by the other participant. In our case, the key idea is to construct an algorithm-free framework above the algorithms themselves, so that one or multiple appropriate algorithms can be selected based on the `appearance' of the object described by the developers.
% The developers can then use the framework's description interface, which is structured to match how vision problems can be described based on a model of a 3D scene and can be translated to parameters useful for determining which algorithms would work best.

% \section{Problem definition}
% The problem we address in this thesis can be described as: construct a mapping with the description of the object as input, returning the best possible reconstruction result by one algorithm from a suite of algorithms.

% \subsection{Scope}
% To limit the scope of this work, we make the following assumptions:

% \subsubsection{Simplified reflectance model}
% Since the majority of reconstruciton techniques rely on observing light reflected off a surface, surfaces exhibit significant effect of global light tranport present a huge challenge to the reconstruction problem. Surface exhibits global light transport, including \textit{specular}, \textit{transmission}, \textit{sub-surface scattering}, \textit{inter-reflection}, \textit{self-shadow}, and etc would break the assumptions made by most generic 3D reconstruction algorithms. Thus the global light transport are ignored, and the reflection properties of consideration are \textit{albedo}, \ie the ratio of reflected light w.r.t the received light, and \textit{specularity}, \ie the amount of specular reflection. A more comprehensive model should be constructed based on our work to incorporate more complex phenomena to be more comprehensive.

% \subsubsection{Simplified geometric model}
% It's a challenging task to model geometry using mathematical descriptions. For geometric primitives such as cube, sphere, or cone, etc, it's possible to describe the shape using concise descriptions. However, the task becomes prohibitive when it comes to shapes with varied characteristics. Furthermore it becomes more ambiguous when natural language is employed. Thus we only consider the microscopic roughness of the surface, which has a direct relation with the reflection. Other prominent geometric properties such as \textit{concavity}, which affects self-shadow, inter-reflection, \textit{depth-discontinuity}, which affects the depth estimation, are ignored.

% \subsubsection{Simplified object class}
% Only a subset of visual/geometric properties are considered, which include texture, lightness, specular, and roughness. Since we use a simplified reflectance and geometric model, phenomena such as translucency, subsurface scattering, refraction, occlusion, concavity can not be described properly. Thus object exhibiting those properties are not considered in the evaluation.

% \subsection{Data}
% We use both a synthetic and a real-world dataset. The synthetic dataset is generated by a physically-based renderer Cycles with varied reflectant and geometric properties, including texture, albedo, specular,and roughness. We used the similar setup to capture real-world images of 11 objects to further test the validity of our proposed abstraction.

\section{Outline}
The problem addressed by this thesis can be described as follows: construct a framework for 3D reconstruction that can return a reliable reconstruction result by one of the best-suited algorithms, which is determined by the description of the problem condition, see Figure~\ref{fig:framework_overview}. More specifically, a taxonomy is proposed that transforms the 3D reconstruction problem from one requiring knowledge of algorithmic details to one that is based on the correlation between the problem space and algorithms. Next, a well defined model and representations are developed to describe the problem space definitively. Lastly, mapping between the problem space and the algorithms is discovered, from which a proof-of-concept interpreter is proposed. A rigorous evaluation is then carried out to verify the effectiveness and robustness of the interpreter. 

The framework consists of the following three layers: the \textit{description layer} sits on top and acts as the interface between the user and the lower layers. It is through this that the user provides a description of the 3D reconstruction problem. The description is passed to the \textit{interpreter} layer, which chooses appropriate algorithms given the description, and then configures each algorithm's parameters. The interpreter can also define any necessary pre or post-processing operations (such as noise removal or image scaling). The lowest layer of the three is where the \textit{algorithms} sit.
\begin{figure}[!htbp]
\centering
\begin{tikzpicture}[node distance=1.2cm, auto]

\node (desc) [data] {L3: Description};
\node (interp) [data, below of=desc] {L2: Interpreter};
\node (algo) [data, below of=interp] {L1: Algorithm};
\draw[red,thick,solid] ($(desc.north west)+(-0.3,0.3)$)  rectangle ($(algo.south east)+(0.3,-0.3)$);

\end{tikzpicture}
\caption{The three layers of the 3D reconstruction framework.}
\label{fig:framework_overview}
\end{figure}

\subsection{Related Work}
We discuss the existing software and toolboxes for 3D reconstruction, and present the required vision background needed to fully take advantage of these toolboxes. A review of the 3D acquisition techniques is also provided, organized by the visual and geometric cues used for reconstruction.

\subsection{A Taxonomy of 3D Reconstruction}
The proposed taxonomy categorizes algorithms based not on how well they work, but on the problem domain that they can reliably work under. First, the problem space is developed, with each axis representing a key property of the object's material or geometry. Next, the selected classes of algorithms are mapped to the problem conditions based on reports in the relevant literature.

\subsection{A Description of 3D Reconstruction}
In previous cases, the mapping from a problem space to an algorithms has been ambigueous due to the problem spaces that are less well-defined. Here, we set out to provide a rigorous definition of the problem space itself. First, a formal and practical definition of the 3D reconstruction problem based on Set Theory is proposed. Second, a model consisting of key object properties is developed. Third, the representations of the problem are proposed. We select key elements that can affect the properties of the model and use them as components of the representation. Lastly, common 3D reconstruction tasks are expressed using the proposed model and representations.
% \begin{figure}[!htbp]
% \centering
% \begin{tikzpicture}[node distance=1.2cm, auto]

% \node (exp) [data] {Expressions};
% \node (rep) [data, below of=exp] {Representation};
% \node (model) [data, below of=rep] {Model};
% \node (def) [data, below of=model] {Definition};
% \draw[red,thick,solid] ($(exp.north west)+(-0.3,0.3)$)  rectangle ($(def.south east)+(0.3,-0.3)$);

% \end{tikzpicture}
% \caption{The three layer of the 3D reconstruction framework.}
% \label{fig:framework_overview}
% \end{figure}

\subsection{A Mapping of 3D Reconstruction}
To derive more precise mapping, we need to evaluate the performance of the selected algorithms under varied properties and their combinations. We use synthetic datasets to achieve this goal. Part of the challenge in establishing a comprehensive set of experiments for such an evaluation is the large variations of shapes and material properties. To overcome this issue, we first establish the \textit{effective problem domain} (EPS) by finding the effective and dependent properties. Then we evaluate the performance of each algorithm under the conditions of all dependent properties and their combinations, which serves as the basis of the mapping.
% \begin{figure}[!htbp]
% \centering
% \begin{tikzpicture}[node distance=1.5cm, auto]

% \node (depend_check) [process] {Denpendency Check};
% \node (prop_set) [data, above of=depend_check, xshift=-2cm, yshift=0.25cm] {Property Set};
% \node (algo) [data, above of=depend_check, xshift=2cm, yshift=0.25cm]{Algo. i};
% \node (depend_prop) [data, below of=depend_check] {Dependent Property Set};
% \node (train) [process, below of=depend_prop] {Training};
% \node (cond_mat) [data, below of=train] {Condition matrix};

% \draw (prop_set.south) -- ++(0.0, -0.25) coordinate (inter0);
% \draw (inter0) -- ++(2.0, 0.0) coordinate (inter1);
% \draw (algo.south) -- ++(0.0, -0.25) coordinate (inter2);
% \draw (inter2) -- ++(-2.0, 0.0) coordinate ();
% \draw [arrow] (inter1) -- (depend_check);
% \draw [arrow] (depend_check) -- (depend_prop);
% \draw [arrow] (depend_prop) -- (train);
% \draw [arrow] (train) -- (cond_mat);
% \draw[red,thick,dotted] ($(prop_set.north west)+(-0.3,0.3)$)  rectangle ($(cond_mat.south east)+(2.3,-0.3)$);

% \end{tikzpicture}
% \caption{The process of obtaining the condition matrix for an algorithm.}
% \label{fig:mapping_overview}
% \end{figure}

\subsection{An Interpretation of 3D Reconstruction}
We conduct the evaluation of the framework around two key evaluation questions: 1) can the derived mapping be extended to an object with a different shape; 2) can the framework return a reliable result given the correct description to the problem condition. To answer these questions, we carry out two separate experiments: 1) we use synthetic objects with the same configurations as the ones used to derive the mapping, and check if the algorithms can return reliable results that are consistent with the mapping; 2) we use real-world objects to test the use of the framework.
% \begin{figure}[ht]
% \centering
% \begin{tikzpicture}[node distance=2cm, auto]
% % depend_check, and training
% \node (depend_check) [process] {Denpendency Check};
% \node (prop_set) [data, above of=depend_check, xshift=-2cm, yshift=0.5cm] {Property Set};
% \node (algo) [data, above of=depend_check, xshift=2cm, yshift=0.5cm]{Algo. i};
% \node (depend_prop) [data, below of=depend_check] {Dependent Property Set};
% \node (train) [process, below of=depend_prop] {Training};
% \node (prfm_algo) [data, below of=train] {Performance of Algo. i};
% \node [data, draw=none, fill=none, left of=prop_set, xshift=-1.2cm] {Chapter~\ref{ch:3DRecon_Mapping}: 3D Benchmark};

% % 3D taxonomy
% \node (algorithm) [model, above of=algo, yshift=1.8cm] {Algorithms};
% \node (translucency) [data_nonfixed, below of=algorithm, xshift=-3.9cm] {Translucency};
% \node (texture) [data_nonfixed, right of=translucency, xshift=0.1cm]{Texture};
% \node (lightness)[data_nonfixed, right of=texture, xshift=-0.2cm]{Lightness};
% \node (reflection)[data_nonfixed, right of=lightness, xshift=0.0cm]{Reflection};
% \node (rough)[data_nonfixed, right of=reflection, xshift=0.1cm]{Roughness};
% \node (3d_taxo) [dotted, draw=red, fill=none, thick, fit=(algorithm) (translucency) (texture) (lightness) (reflection) (rough), inner sep=0.3cm] {};
% \node [data, draw=none, fill=none, above of=3d_taxo, yshift=0.4cm] {Chapter~\ref{ch:3DRecon_Taxo}: 3D Taxonomy};

% % 3D interpretation
% \node (abstract) [process, below of=prfm_algo]{Mapping};
% \node (best_algo) [data, right of=abstract, xshift=2cm] {Best-suited algorithm(s)};
% \node [data, draw=none, fill=none, below of=abstract, yshift=0.4cm] {Chapter~\ref{ch:3DRecon_Interp}: 3D Interpretation};

% % 3D model
% \node (def) [data, left of=abstract, xshift=-3cm, yshift=6cm)] {Definition};
% \node (model) [data, below of=def] {Model};
% \node (rep) [data, below of=model] {Representation};
% \node (exp) [data, below of=rep] {Expressions};
% \node [data, draw=none, fill=none, above of=def, yshift=-0.5cm] {Chapter~\ref{ch:3DRecon_Desc}: 3D Model};

% % depend_check, and training
% \draw (prop_set.south) -- ++(0.0, -0.5) coordinate (inter0);
% \draw (inter0) -- ++(2.0, 0.0) coordinate (inter1);
% \draw (algo.south) -- ++(0.0, -0.5) coordinate (inter2);
% \draw (inter2) -- ++(-2.0, 0.0) coordinate ();
% \draw [arrow] (inter1) -- (depend_check);
% \draw [arrow] (depend_check) -- (depend_prop);
% \draw [arrow] (depend_prop) -- (train);
% \draw [arrow] (train) -- (prfm_algo);
% \draw [arrow] (prfm_algo) -- (abstract);
% \draw[red,thick,dotted] ($(prop_set.north west)+(-0.3,0.3)$)  rectangle ($(prfm_algo.south east)+(2.3,-0.3)$);

% \draw (algorithm.south) -- ++(0.0, -0.5) coordinate (c);
% \draw (c) -- ++(-1.8, 0.0) coordinate (n1);
% \draw [arrow](n1) -- (texture.north);
% \draw (n1) -- ++(-2.1, 0.0) coordinate (n2);
% \draw [arrow](n2) -- (translucency.north);
% \draw [arrow](c) -- (lightness.north);
% \draw (c) -- ++(2.0, 0.0) coordinate (p1);
% \draw [arrow](p1) -- (reflection.north);
% \draw (p1) -- ++(2.1, 0.0) coordinate (p2);
% \draw [arrow](p2) -- (rough.north);
% \draw [arrow] (3d_taxo) -- (algo);

% % 3D model
% \draw (def) -- (model);
% \draw (model) -- (rep);
% \draw (rep) -- (exp);
% \draw [arrow] (exp) -- (abstract);
% \draw[red,thick,dotted] ($(def.north west)+(-0.3,0.3)$)  rectangle ($(exp.south east)+(0.3,-0.3)$);

% % 3D interpretation
% \draw [arrow] (abstract) -- (best_algo);
% \draw[red,thick,dotted] ($(exp.north west)+(-0.3,0.3)$)  rectangle ($(best_algo.south east)+(0.3,-0.3)$);
% \end{tikzpicture}
% \caption{Thesis overview. Rectangles denote process. Rounded rectangles represents data or component.}
% \label{fig:system_overview}
% \end{figure}

\section{Contributions}
The main contribution of this thesis is the development and evaluation of a framework for the 3D reconstruction problem in computer vision, to hide the details of specific methods. An abstraction may be employed by users to describe the conditions of the vision problems they are trying to solve, and our novel interpreter uses such descriptions to select an appropriate algorithm and return a reliable result. This endeavor is non-trivial for two reasons: 1). currently, not one approach can achieve satisfactory results for an object with general material and geometric properties. Our framework can, to an extent, solve this problem by incorporating multiple algorithms that are designed for a range of problem conditions; 2). a solid understanding of reconstruction algorithm details is a prerequisite to fully take advantage of the existing techniques, which is difficult for general developers to obtain. The descriptive language proposed in this thesis can allow application developers to bypass the aforementioned hurdles, and thus is a developer-friendly approach. The significant aspects of our approach are presented in further detail below:

\noindent\textbf{1. A taxonomy of the 3D reconstruction problem that focuses on problem conditions instead of algorithmic details.}

Typical taxonomies generally focus on one class of algorithms and are algorithm centric. Normally they describe and classify intra-class algorithms based on \textit{how} an algorithm solves a problem. For instance, MVS algorithms can be categorized based on visibility models or scene representations, and PS methods can be classified by reflectance models. While this type of taxonomy provides a decent basis for comparison of intra-class algorithms, it provides little insight into the conditions where techniques can perform well, which is crucial when it comes to designing an application that requires reliable reconstruction techniques. Thus this thesis introduces a new perspective of taxonomy for 3D reconstruction that is based on the conditions surrounding the problem. Further, we address the lack of progress in certain areas of this research field, which will be helpful for redirecting research efforts to less explored territories.

\noindent\textbf{2. A description of the 3D reconstruction problem that allows increased precision in mapping from a well-defined problem space to algorithms.}

Much of the recent research in this area has been focused on technical novelties. However, we need to pay equal attention to the conditions under which algorithms are designed, in order to return reliable results. One of the reasons for this oversight is the ambiguity of the problem domain. Information regarding the set of conditions under which a given algorithm performs well is difficult to convey without an agreed upon model representing the problem space itself. Conversely, knowledge of which algorithm best suits a particular set of conditions in the problem space is also difficult to determine without a model to represent such conditions. Therefore, it's crucial to have a better understanding of the problem space so that we can exploit the working space of algorithms.

\noindent\textbf{3. A mapping from the description of the object to appropriate algorithms.}

Given an algorithm, the conditions under which this specific algorithm works well is largely unclear. Additionally, given a specific problem conition, the knowledge of which algorithm performs well under this problem condition is empirical. Therefore, we need to find a precise mapping from the well defined problem space to determine a reliable solution. Here the effective conditions of a specific algorithm is discovered by evaluating performance under the well defined problem conditions.

% \noindent\textbf{4. The development and evaluation of the mapping of 3D reconstruction.}

% The construction of the mapping allows more accurate mapping. However, different from the previous research working on algorithms, the evaluation is more complicated and sophisticated. The reason for such an evaluation is that the mapping is for more general objects and algorithms, thus it requires a wider test cases, and rigorous experiment design. 

\section{Organization}
We organize this thesis as follows. First we will discuss related works in Chapter~\ref{ch:RelatedWork}. In Chapter~\ref{ch:3DRecon_Taxo}, we provide a taxonomy of 3D reconstruction based on the conditions surrounding a problem. In Chapter~\ref{ch:3DRecon_Desc}, we provide a formal description of the 3D reconstruction problem, which can be applied to current existing techniques. In Chapter~\ref{ch:3DRecon_Mapping}, we discuss the process of generating a synthetic dataset to evaluate the performance of a selected set of techniques under varied problem conditions, from which a mapping can be derived. In Chapter~\ref{ch:3DRecon_Interp}, we use both synthetic and real-world datasets to demonstrate the interpretation of the 3D reconstruction description and the validity of the proposed mapping.