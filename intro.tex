%% The following is a directive for TeXShop to indicate the main file
%%!TEX root = diss.tex

\chapter{Introduction}
\label{ch:Introduction}
% [introduction to 3D reconstruction]\\
Modelling of the 3D world has been an active research topic in computer vision for decades and has a wide range of applications including 3D mapping and navigation, online shopping, 3D printing, computational photography, video games, visual effects, and cultural heritage archival. The goal of 3D modelling is to reconstruct a 3D model represented by point cloud, voxel grid, depth maps, or surface mesh, from RGB or range sensors, optionally incorporating the material of the surface.

% [current situation and context]\\
Achieving this goal is an extremely challenging task, as it involves the reverse process of image formation, which is highly likely to result in a variety of possible results and solutions. To overcome this challenge, some assumptions must be made in terms of materials, viewpoints, and lighting conditions. In turn, a solid understanding of the interaction of light with surface geometry and material is a prerequisite to fully take advantage of the existing techniques. In the past decades, we have witnessed a variety of tools and approaches to 3D modelling applied successfully to an assortment of sub-domains, such as Computer Aided Design (CAD) tools~\cite{CAD}, arm-mounted probes, active methods~\cite{bernardini2002building,levoy2000digital,Lidar,kinect} and passive image-based methods~\cite{kutulakos2000theory,furukawa2010accurate,faugeras2002variational,goesele2006multi}. Among the existing approaches, active techniques such as laser scanners~\cite{levoy2000digital}, Structured Light (SL) systems~\cite{bernardini2002building}, and Photometric Stereo (PS)~\cite{woodham1980photometric}, as well as passive methods such as Multi-View Stereo (MVS)~\cite{seitz2006comparison}, have been the most successful. Laser scanners and structured light techniques are seen to generate the most accurate results, but are generally complicated to calibrate, time consuming to scan, and demanding in terms of storing and processing. Photometric Stereo is able to achieve highly detailed reconstruction comparable to that of laser scanners, but the true depth information is lost due to the use of a single viewpoint. Further, MVS requires minimal setup and can work in both controlled, small scale lab settings as well as outdoor, medium to large scale environments. However, the quality of reconstruction is generally noisier, and is susceptible to texture and material property of the surface. All of the aforementioned techniques requires an understanding of calibration, stereo correspondence, physics-based vision, and so on, which are not easy tasks to master.

% [motivation]\\
Regardless of past success and strong demands across various areas, we have not yet witnessed any substantial progress in terms of making the mentioned techniques accessible to application developers or system designers (termed \textit{users} for the rest of the thesis), who generally have little or no computer vision expertise. We've made two key observations about computer vision algorithms: 1) few of these methods work well under all circumstances, nor do they share the same setup or inputs/outputs, making it difficult for developers to choose an optimal method for their particular application; 2) expertise knowledge is a prerequisite to fully exploit the potentials of existing vision techniques. These observations lead us to the following question which we address in this thesis: is it achievable to create an interface that can return a reliable reconstruction by one of the best possible algorithms based on the descriptions of the object or scene to be reconstructed?

The interface consists of the following three layers, see Figure~\ref{fig:interface_overview}: the \textit{description layer} sits on top and acts as the medium between the user and the lower layers. It is through this that the user provides a description of the 3D reconstruction problem. The description is passed to the \textit{interpreter} layer, which chooses appropriate algorithms given the description, and then configures each algorithm's parameters. The interpreter can also define any necessary pre- or post-processing operations (such as noise removal or image scaling). The lowest layer of the three is where the \textit{algorithms} sit.
\begin{figure}[!htbp]
\centering
\begin{tikzpicture}[node distance=1cm, auto]

\node (desc) [data] {L3: Description};
\node (interp) [data, below of=desc] {L2: Interpreter};
\node (algo) [data, below of=interp] {L1: Algorithm};
% \draw[red,thick,solid] ($(desc.north west)+(-0.3,0.3)$)  rectangle ($(algo.south east)+(0.3,-0.3)$);

\end{tikzpicture}
\caption{The three layers of the 3D reconstruction interface.}
\label{fig:interface_overview}
\end{figure}

% The mental model to our approach is similar to that of the game `name that object': one participant makes guesses of what the object is based solely on the descriptions of the appearance provided by the other participant. In our case, the key idea is to construct an algorithm-free interface above the algorithms themselves, so that one or multiple appropriate algorithms can be selected based on the `appearance' of the object described by the developers.

\section{Motivating scenario}
We propose a scenario to further emphasize and justify the motivation: Ben is an engineer for 3DSense, a company designing and manufacturing 3D capturing systems and software. It is Ben's job to design 3D camera rigs and related software for 3D capturing tasks. Ben has a background on software engineering while very limited computer vision knowledge. Daisy, a visual effects artist, wants a 3D modelling system that is able to reconstruct real world objects for her projects. She has little programming experience, but is highly skilled at 3D modelling tools. See Figure~\ref{fig:scenario_user} for more details of their backgrounds respectively.
\begin{figure}[!htbp]
\centering
\includegraphics[width=\textwidth]{img/intro/scenario.pdf}
\caption{Two target user of the proposed scenario.}
\label{fig:scenario_user}
\end{figure}

Ben starts by looking into general computer vision libraries and existing 3D reconstruction techniques, and comes across a general vision library called OpenCV, several multi-view stereo software (PMVS, MVE), a photometric stereo technique called example-based PS, and a structured light technique called Gray-coded SL. Since he fails to find any out-of-box 3D reconstruction algorithms implemented in OpenCV, he decides to use the existing techniques instead. He develops a software that integrates multiple algorithms, and provides a window to tune algorithm-specific parameters, as shown in Figure~\ref{fig:scenario_app} (a). Ben builds a multi-purpose camera rig with camera-projector pairs and light sources, that is able to capture appropriate images for algorithms across varied categories, including MVS, PS, SL, and VH techniques. More specifically, the rig consists of three rings of camera-projector pairs, each positioned at a zenith angle of $15^\circ$, $45^\circ$, and $75^\circ$. The azimuth angle between two neighbouring cameras is $30^\circ$. The light sources are positioned so that no camera views are blocked. He first tests the system with a \textit{white porcelain cup}, and selects PMVS as the reconstruction algorithm. The `parameter' window displays a list of parameters to tune this specific algorithm, including \underline{window size}, \underline{cell size}, \underline{photo-consistency measure}, and seven other parameters, the effects of which are largely unclear. He runs the software using the default parameter settings since he is unaware of the effects of these parameters. The reconstructed result turns out to be very poor in the sense that the surface is not smooth and contains many holes. He suspects that this is due to the settings of the parameters. He tries to increase the \underline{cell size} while fixing the other parameters, which leads to a even sparser result. After multiple `trial-and-error', the software still fails to achieve a successful result. Ben decides to try out another library called OpenVL, which is able to produce a successful solution by selecting one of the underlying algorithms given a description of appearance of the object. He writes a software that allows the users to simulate the appearance of an object by tuning visual and geometric parameters using sliders, including texture, albedo, specularity, and roughness, as shown in Figure~\ref{fig:scenario_app} (b). The `visualization' window displays a synthetic object, showing the effects of these parameters. The software then invokes the API to run reconstruction once an algorithm is selected by the interpreter. Ben places the \textit{white porcelain cup} inside the camera rig and moves the sliders until the synthetic object resembles that of the target object. The parameter settings are as follows: 0.2 (texture), 0.8 (albedo), 0.8(specularity), 0.2 (roughness). He then presses the `reconstruction' button, the algorithm EPS is selected by the underlying interpreter, and a successful result is obtained. After some refinements of the camera rig and the software, Ben sends the prototype to the testing team for further testing.

% he decides to try out PMVS instead. He builds a multi-view camera rig with sufficient overlapping between neighbouring cameras. More specifically, the rig consists of three rings of cameras, each positioned at a zenith angle of $15^\circ$, $45^\circ$, and $75^\circ$. The azimuth angle between two neighbouring cameras is $30^\circ$. He writes a software based on PMVS and provides an interface for parameter settings to fine tune the algorithm, including \underline{window size}, \underline{cell size}, \underline{photo-consistency measure}, and seven other parameters, the effects of which are largely unclear. He places a \textit{white porcelein cup} inside the camera rig and starts the image capturing process. He runs the software using the default parameter settings. The reconstructed result turns out to be very poor in the sense that the surface is no longer smooth and contains many holes. He suspects that this is due to the settings of the parameters. He tries to increase the \underline{cell size} while fixing the other parameters, which leads to a even sparser result. After multiple `trial-and-error', the software still fails to achieve a successful result.


% which provides an interface that allows the user to describe the appearance of an object (called \textit{problem condition}), from which the built-in interpreter selects a reliable algorithm from a suite of algorithms across different categories. The current implementation of the library includes algorithms from four categories: MVS, PS, SL, and VH, with the capability of incorporating new algorithms once they become available. The library provides parameters regarding the visual and geometric properties of an object, which can be visually estimated and tuned through simulation. The product is later launched in limited amount as a developer kit.

Daisy the 3D artist, is invited to a user testing of the 3D modelling system by 3DSense. She starts by placing a \textit{white porcelain vase} inside the camera rig and opens the software. She sees a parameter configuration interface with several sliders labelled with visual and geometric properties, including `texture', `albedo', `specularity', and `roughness'. She moves the slides and observes that the synthetic object displays the effect of the property immediately. After some practice, she starts to tune the visual parameters of the target object: she moves each slider until the synthetic object appears to have the same appearance as the target object. The settings are as follows: 0.2 (texture), 0.8 (albedo), 0.8 (specularity), and 0.8 (roughness). The interpreter then selects GSL as the reconstruction algorithm, and proceeds to capture the input images using the camera rig for reconstruction. However, there are noticeable holes on the reconstructed model. She observes that this ceramic vase is highly smooth and glossy, thus decides to set `roughness' to 0.2. The interpreted algorithm becomes EPS, and the reconstruction result turns out to be smooth and with no surface holes. Daisy is curious to see how sensitive the interpreter is with respect to less accurate descriptions. She sets the parameters to the complete opposite, \ie 0.8 (texture), 0.2 (albedo), 0.2 (specularity), and 0.8 (roughness). This time, PMVS is selected by the interpreter, and a noisy reconstructed model is obtained. She then proceeds to do the same with all her objects including a bust, statue tuning each of the properties before doing the reconstruction.
\begin{figure}[!htbp]
\centering
\begin{tabular}{cc}
\includegraphics[width=0.445\textwidth]{img/intro/motivation.pdf} &
\includegraphics[width=0.5\textwidth]{img/intro/motivation1.pdf}\\
(a). Traditional 3D reconstruction & (b). Interface of 3D reconstruction \\
\end{tabular}
\caption{Scenario of using the traditional approach and the proposed interface for 3D reconstruction tasks.}
\label{fig:scenario_app}
\end{figure}

% Ben decides to try the Structured Light technique. He enchances the existing camera rig by pairing each camera with a projector. He tests the system using the same \textit{white matte statue} and achieves a successful reconstruction result. On the weekly design meeting, Tom the manager tests the system with a \textit{matte pot}, and achieves a successful result. However, when he tries to reconstruct a \textit{shiny porceilain cup}, neither of these two techniques give a reliable result: PMVS gives noisy and incomplete reconstruction, and SL fails to reconstruct the glossy areas. Further, the manager complains that he does not have a clue of which algorithm to choose for a specific object or scene, and the effect and interpretation of the parameters are unclear and confusing since he does not have a background in vision. He challenges Ben if he can come up with a better way to \textit{determine a reliable algorithm given a specific object without multiple `try-and-error', and provide a more perceptually intuitive and interpretable parameters} so that the users don't have to deal with algorithm-level parameters. Ben consults a computer vision researcher, Mark, and is informed that most 3D vision algorithms only work under a limited range of conditions. For instance, PMVS, a multi-view stereo algorithm, typically fails work well on textureless surfaces, and typical SL works poorly on specular surfaces. Mark suggests Ben to try a vision library called OpenVL, which provides an interface that allows the user to describe the appearance of the object (called \textit{problem condition}), from which the built-in interpreter selects a reliable algorithm from a suite of algorithms across different categories. Ben starts to design a multi-purpose camera rig that is capable of capturing images for multiple classes of algorithms, which includes MVS, PS, and SL. He implements a software using OpenVL's API, which accpets user-specified problem condition as input, thus hiding algorithm details from users with little vision background. The problem condition consists of various visual and geometric properties, such as texture, specularity level, and so on. The reconstruction process is as follows: first, the user uses the synthetic toolbox provided by OpenVL to estimate property parameter by visualizing and comparing the synthetic object to the real object. Next, the estimated properties are used as description of problem condition, and fed into the software, which in turn invokes the build-in interpreter to select a reliable algorithm (interpreted algorithm). Lastly, the interpreted algorithm uses corresponding images captured by the camera rig for reconstruction. In the case of a \textit{white porcelein cup}, a structured light technique is selected given the user-specified description. The SL algorithm implemented within OpenVL framework uses the images captured by the camera rig for reconstruction, and a successful 3D model is generated. Ben tests the new capturing system and software using objects with a wide range of visual and geometric properties and achieves successful reconstruction results.

% He use the toolbars to tune the parameters of these properties and visulize the result for comparison. Once the parameters are determined, they are fed into the software, which invoke the build-in interpreter to select a reliable algorithm.

% three cameras which are positioned at different heights on a spherical arm. The camera rig rotates $30^\circ$ at a time, and at each position, three images are taken. Thus the total number of images is 36. 

% prototype with three camera-projector pairs mounted on a spherical arm, which rotates about the center $30^\circ$ at a time, and captures images of the matte statue. He uses the default parameters of the SL algorithm and achieves successful reconstruction result.

% There are three camera-projector pairs, and 25 light sources. The camera-projector pair rotates $30^\circ$ at a time. 

\section{Outline}
The problem addressed in this thesis can be described as follows: construct an interface for 3D reconstruction that can return a reliable reconstruction result by one of the best-suited algorithms, which is determined by the description of the problem condition. More specifically, a problem space is proposed that transforms the 3D reconstruction problem from one requiring knowledge of algorithm details to one that is based on the relation between the problem condition and algorithms. Next, a well defined model and representations are developed to describe the problem space definitively. Lastly, mapping between the problem space and the algorithms is discovered, from which a proof of concept interpreter is proposed. An evaluation is then carried out to verify the robustness of the interpreter.

\subsection{Related Work}
We discuss the existing software and toolboxes for 3D reconstruction, and present the required vision background needed to fully take advantage of these toolboxes. A review of the 3D acquisition techniques is provided, organized by the visual and geometric cues used for reconstruction.

\subsection{A Problem space of 3D Reconstruction}
Existing approaches to 3D reconstruction focus more on providing algorithm solutions to problems, which we call an \textit{algorithm-centred approach}. This approach provides little insight to the problem conditions that a specific algorithm is applicable to. We proposed a \textit{problem-centred approach} that gives a well-defined problem space, which allows further investigation of the relation between problem conditions and algorithms (termed \textit{mapping} in this thesis). This mapping can be used to choose a best possible algorithm based on a described problem condition. The problem condition consists of a variety of visual and geometric properties of objects. The aggregate problem conditions is called \textit{problem space}.

\subsection{A Description of 3D Reconstruction}
In previous cases, the mapping from a problem condition to an algorithm has been ambiguous due to the problem space that is poorly defined. Here, we set out to provide a rigorous description of the problem condition itself. First, a model consisting of key object properties is developed. Second, the representations of the problem space are proposed. Lastly, common 3D reconstruction tasks are expressed using the proposed model and representations.
% First, a formal and practical definition of the 3D reconstruction problem based on set theory is proposed.
% \begin{figure}[!htbp]
% \centering
% \begin{tikzpicture}[node distance=1.2cm, auto]

% \node (exp) [data] {Expressions};
% \node (rep) [data, below of=exp] {Representation};
% \node (model) [data, below of=rep] {Model};
% \node (def) [data, below of=model] {Definition};
% \draw[red,thick,solid] ($(exp.north west)+(-0.3,0.3)$)  rectangle ($(def.south east)+(0.3,-0.3)$);

% \end{tikzpicture}
% \caption{The three layer of the 3D reconstruction interface.}
% \label{fig:interface_overview}
% \end{figure}

\subsection{A Mapping of 3D Reconstruction}
To derive a more precise mapping from problem space to algorithms, we need to evaluate the performance of selected algorithms under varied properties and their combinations. We use synthetic datasets to achieve this goal. The main challenge in conducting such a comprehensive evaluation is the large variations of shape and material properties. To overcome this issue, we first discover properties that have main and interaction effect on algorithm performance (termed \textit{effective property}). Then we evaluate the performance of each algorithm under the conditions of these \textit{effective properties}, which serves as the basis of the mapping.
% \begin{figure}[!htbp]
% \centering
% \begin{tikzpicture}[node distance=1.5cm, auto]

% \node (depend_check) [process] {Denpendency Check};
% \node (prop_set) [data, above of=depend_check, xshift=-2cm, yshift=0.25cm] {Property Set};
% \node (algo) [data, above of=depend_check, xshift=2cm, yshift=0.25cm]{Algo. i};
% \node (depend_prop) [data, below of=depend_check] {Dependent Property Set};
% \node (train) [process, below of=depend_prop] {Training};
% \node (cond_mat) [data, below of=train] {Condition matrix};

% \draw (prop_set.south) -- ++(0.0, -0.25) coordinate (inter0);
% \draw (inter0) -- ++(2.0, 0.0) coordinate (inter1);
% \draw (algo.south) -- ++(0.0, -0.25) coordinate (inter2);
% \draw (inter2) -- ++(-2.0, 0.0) coordinate ();
% \draw [arrow] (inter1) -- (depend_check);
% \draw [arrow] (depend_check) -- (depend_prop);
% \draw [arrow] (depend_prop) -- (train);
% \draw [arrow] (train) -- (cond_mat);
% \draw[red,thick,dotted] ($(prop_set.north west)+(-0.3,0.3)$)  rectangle ($(cond_mat.south east)+(2.3,-0.3)$);

% \end{tikzpicture}
% \caption{The process of obtaining the condition matrix for an algorithm.}
% \label{fig:mapping_overview}
% \end{figure}

\subsection{An Interpretation of 3D Reconstruction}
We conduct the evaluation of the interface around three key evaluation questions: 1) can the proof of concept interpreter return one of the best-suited algorithms that achieves a successful reconstruction given the correct description; 2) will a less accurate description give a poorer reconstruction result; 3) will an inaccurate description give a poor reconstruction result. To answer these questions, we carry out three separate experiments, use synthetic and real-world datasets to evaluate the interpreter in Section~\ref{sec:eval_interp}.
% \begin{figure}[ht]
% \centering
% \begin{tikzpicture}[node distance=2cm, auto]
% % depend_check, and training
% \node (depend_check) [process] {Denpendency Check};
% \node (prop_set) [data, above of=depend_check, xshift=-2cm, yshift=0.5cm] {Property Set};
% \node (algo) [data, above of=depend_check, xshift=2cm, yshift=0.5cm]{Algo. i};
% \node (depend_prop) [data, below of=depend_check] {Dependent Property Set};
% \node (train) [process, below of=depend_prop] {Training};
% \node (prfm_algo) [data, below of=train] {Performance of Algo. i};
% \node [data, draw=none, fill=none, left of=prop_set, xshift=-1.2cm] {Chapter~\ref{ch:3DRecon_Mapping}: 3D Benchmark};

% % 3D taxonomy
% \node (algorithm) [model, above of=algo, yshift=1.8cm] {Algorithms};
% \node (translucency) [data_nonfixed, below of=algorithm, xshift=-3.9cm] {Translucency};
% \node (texture) [data_nonfixed, right of=translucency, xshift=0.1cm]{Texture};
% \node (lightness)[data_nonfixed, right of=texture, xshift=-0.2cm]{Lightness};
% \node (reflection)[data_nonfixed, right of=lightness, xshift=0.0cm]{Reflection};
% \node (rough)[data_nonfixed, right of=reflection, xshift=0.1cm]{Roughness};
% \node (3d_taxo) [dotted, draw=red, fill=none, thick, fit=(algorithm) (translucency) (texture) (lightness) (reflection) (rough), inner sep=0.3cm] {};
% \node [data, draw=none, fill=none, above of=3d_taxo, yshift=0.4cm] {Chapter~\ref{ch:3DRecon_Taxo}: 3D Taxonomy};

% % 3D interpretation
% \node (abstract) [process, below of=prfm_algo]{Mapping};
% \node (best_algo) [data, right of=abstract, xshift=2cm] {Best-suited algorithm(s)};
% \node [data, draw=none, fill=none, below of=abstract, yshift=0.4cm] {Chapter~\ref{ch:3DRecon_Interp}: 3D Interpretation};

% % 3D model
% \node (def) [data, left of=abstract, xshift=-3cm, yshift=6cm)] {Definition};
% \node (model) [data, below of=def] {Model};
% \node (rep) [data, below of=model] {Representation};
% \node (exp) [data, below of=rep] {Expressions};
% \node [data, draw=none, fill=none, above of=def, yshift=-0.5cm] {Chapter~\ref{ch:3DRecon_Desc}: 3D Model};

% % depend_check, and training
% \draw (prop_set.south) -- ++(0.0, -0.5) coordinate (inter0);
% \draw (inter0) -- ++(2.0, 0.0) coordinate (inter1);
% \draw (algo.south) -- ++(0.0, -0.5) coordinate (inter2);
% \draw (inter2) -- ++(-2.0, 0.0) coordinate ();
% \draw [arrow] (inter1) -- (depend_check);
% \draw [arrow] (depend_check) -- (depend_prop);
% \draw [arrow] (depend_prop) -- (train);
% \draw [arrow] (train) -- (prfm_algo);
% \draw [arrow] (prfm_algo) -- (abstract);
% \draw[red,thick,dotted] ($(prop_set.north west)+(-0.3,0.3)$)  rectangle ($(prfm_algo.south east)+(2.3,-0.3)$);

% \draw (algorithm.south) -- ++(0.0, -0.5) coordinate (c);
% \draw (c) -- ++(-1.8, 0.0) coordinate (n1);
% \draw [arrow](n1) -- (texture.north);
% \draw (n1) -- ++(-2.1, 0.0) coordinate (n2);
% \draw [arrow](n2) -- (translucency.north);
% \draw [arrow](c) -- (lightness.north);
% \draw (c) -- ++(2.0, 0.0) coordinate (p1);
% \draw [arrow](p1) -- (reflection.north);
% \draw (p1) -- ++(2.1, 0.0) coordinate (p2);
% \draw [arrow](p2) -- (rough.north);
% \draw [arrow] (3d_taxo) -- (algo);

% % 3D model
% \draw (def) -- (model);
% \draw (model) -- (rep);
% \draw (rep) -- (exp);
% \draw [arrow] (exp) -- (abstract);
% \draw[red,thick,dotted] ($(def.north west)+(-0.3,0.3)$)  rectangle ($(exp.south east)+(0.3,-0.3)$);

% % 3D interpretation
% \draw [arrow] (abstract) -- (best_algo);
% \draw[red,thick,dotted] ($(exp.north west)+(-0.3,0.3)$)  rectangle ($(best_algo.south east)+(0.3,-0.3)$);
% \end{tikzpicture}
% \caption{Thesis overview. Rectangles denote process. Rounded rectangles represents data or component.}
% \label{fig:system_overview}
% \end{figure}

\section{Contributions}
% The main contribution of this thesis is the development and evaluation of a interface for the 3D reconstruction problem in computer vision, to hide the details of specific methods. An abstraction may be employed by users to describe the conditions of the vision problems they are trying to solve, and our novel interpreter uses such descriptions to select an appropriate algorithm and return a reliable result.
The main contribution of this thesis is the development and application of an interface for a subset of 3D reconstruction problem, which hides algorithm details and allows users to describe conditions surrounding the problem. We focus on a subset of problem, which is defined in Chapter~\ref{ch:3DRecon_ProbSpace}, to approach this problem in a tractable manner. This described condition, which consists of varied visual and geometric properties, can be interpreted so that an appropriate algorithm is chosen to reconstruct a successful result. This endeavour is non-trivial for two reasons: 1) currently, most approaches can only achieve satisfactory results on a limited set of categories of objects; 2) a solid understanding of reconstruction algorithm details is a prerequisite to fully take advantage of the existing techniques, which is difficult for application developers to obtain. To some extent, our interface attempts to address a broader problem space by incorporating multiple algorithms. Though it covers a wider range of problem space than a single algorithm, it is still confined within the space covered by the existing techniques within the interface. Thus, our evaluation is carried out within the problem space covered by the selected algorithms.
% The significant aspects of our approach are presented in further detail below:

% \noindent\textbf{1. A taxonomy of the 3D reconstruction problem that focuses on problem conditions instead of algorithm details.}

% Typical taxonomies generally focus on one class of algorithms and are algorithm centric. Normally they describe and classify intra-class algorithms based on \textit{how} an algorithm solves a problem. For instance, MVS algorithms can be categorized based on visibility models or scene representations, and PS methods can be classified by reflectance models. While this type of taxonomy provides a decent basis for comparison of intra-class algorithms, it provides little insight into the conditions where techniques can perform well, which is crucial when it comes to designing an application that requires reliable reconstruction techniques. Thus this thesis introduces a new perspective of taxonomy for 3D reconstruction that is based on the conditions surrounding the problem. Further, we address the lack of progress in certain areas of this research field, which will be helpful for redirecting research efforts to less explored territories.

% \noindent\textbf{2. A description of the 3D reconstruction problem that allows increased precision in mapping from a well-defined problem space to algorithms.}

% Much of the recent research in this area has been focused on technical novelties. However, we need to pay equal attention to the conditions under which algorithms are designed, in order to return reliable results. One of the reasons for this oversight is the ambiguity of the problem domain. Information regarding the set of conditions under which a given algorithm performs well is difficult to convey without an agreed upon model representing the problem space itself. Conversely, knowledge of which algorithm best suits a particular set of conditions in the problem space is also difficult to determine without a model to represent such conditions. Therefore, it's crucial to have a better understanding of the problem space so that we can exploit the working space of algorithms.

% \noindent\textbf{3. A mapping from the description of the object to appropriate algorithms.}

% Given an algorithm, the conditions under which this specific algorithm works well is largely unclear. Additionally, given a specific problem conition, the knowledge of which algorithm performs well under this problem condition is empirical. Therefore, we need to find a precise mapping from the well defined problem space to determine a reliable solution. Here the effective conditions of a specific algorithm is discovered by evaluating performance under the well defined problem conditions.

\section{Organization}
We organize this thesis as follows. Chapter~\ref{ch:RelatedWork} briefly introduces 3D reconstruction toolboxes and gives an overview of current landscape of 3D reconstruction field. In Chapter~\ref{ch:3DRecon_ProbSpace}, we propose a simplified problem space of 3D reconstruction problems and propose four problem conditions that will be investigated in depth. In Chapter~\ref{ch:3DRecon_Desc}, we provide a formal description of problem condition of a 3D reconstruction problem. In Chapter~\ref{ch:3DRecon_Mapping}, we develop the relation from problem condition to algorithms by evaluating the performance of a selection of algorithms under varied problem conditions. In Chapter~\ref{ch:3DRecon_Interp}, we use both synthetic and real-world datasets to demonstrate the interpretation of the user specified description and the robustness of the proof of concept interpreter.
